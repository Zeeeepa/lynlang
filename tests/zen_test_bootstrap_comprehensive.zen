// Comprehensive Bootstrap Compiler Test
// Tests all aspects of the self-hosted Zen compiler

core := @std.core
io := @std.io
test := @std.test
string := @std.string
vec := @std.vec

// Import compiler modules
lexer := @compiler.lexer
parser := @compiler.parser
type_checker := @compiler.type_checker
codegen := @compiler.codegen

// Test suite for lexer
test_lexer_comprehensive = () bool {
    io.print("Testing lexer...\n")
    
    // Test 1: Basic tokens
    input1 := "x := 42"
    lex1 := lexer.new(input1)
    tokens1 := lexer.tokenize(lex1)
    
    token_count := vec.len(tokens1)
    if token_count != 4 { // x, :=, 42, EOF
        io.print("  ✗ Failed: Basic token count\n")
        return false
    }
    io.print("  ✓ Basic tokens\n")
    
    // Test 2: String literals
    input2 := "msg := \"Hello, World!\""
    lex2 := lexer.new(input2)
    tokens2 := lexer.tokenize(lex2)
    
    if vec.len(tokens2) != 4 { // msg, :=, string, EOF
        io.print("  ✗ Failed: String literal tokenization\n")
        return false
    }
    io.print("  ✓ String literals\n")
    
    // Test 3: Comments
    input3 := "x := 1 // comment\ny := 2"
    lex3 := lexer.new(input3)
    tokens3 := lexer.tokenize(lex3)
    
    // Comments should be skipped
    if vec.len(tokens3) != 7 { // x, :=, 1, y, :=, 2, EOF
        io.print("  ✗ Failed: Comment handling\n")
        return false
    }
    io.print("  ✓ Comments\n")
    
    // Test 4: Operators
    input4 := "a + b * c - d / e"
    lex4 := lexer.new(input4)
    tokens4 := lexer.tokenize(lex4)
    
    if vec.len(tokens4) != 10 { // a, +, b, *, c, -, d, /, e, EOF
        io.print("  ✗ Failed: Operator tokenization\n")
        return false
    }
    io.print("  ✓ Operators\n")
    
    // Test 5: Keywords
    input5 := "if true { return false } else { return true }"
    lex5 := lexer.new(input5)
    tokens5 := lexer.tokenize(lex5)
    
    // Should recognize all keywords
    io.print("  ✓ Keywords\n")
    
    return true
}

// Test suite for parser
test_parser_comprehensive = () bool {
    io.print("Testing parser...\n")
    
    // Test 1: Variable declarations
    input1 := "x := 42\ny: i32 = 100"
    lex1 := lexer.new(input1)
    tokens1 := lexer.tokenize(lex1)
    p1 := parser.new(tokens1)
    ast1 := parser.parse_program(p1)
    
    if parser.has_errors(p1) {
        io.print("  ✗ Failed: Variable declarations\n")
        return false
    }
    io.print("  ✓ Variable declarations\n")
    
    // Test 2: Function declarations
    input2 := "add = (a: i32, b: i32) i32 { return a + b }"
    lex2 := lexer.new(input2)
    tokens2 := lexer.tokenize(lex2)
    p2 := parser.new(tokens2)
    ast2 := parser.parse_program(p2)
    
    if parser.has_errors(p2) {
        io.print("  ✗ Failed: Function declarations\n")
        return false
    }
    io.print("  ✓ Function declarations\n")
    
    // Test 3: Struct declarations
    input3 := "Point = { x: f64, y: f64 }"
    lex3 := lexer.new(input3)
    tokens3 := lexer.tokenize(lex3)
    p3 := parser.new(tokens3)
    ast3 := parser.parse_program(p3)
    
    if parser.has_errors(p3) {
        io.print("  ✗ Failed: Struct declarations\n")
        return false
    }
    io.print("  ✓ Struct declarations\n")
    
    // Test 4: Control flow
    input4 := "if x > 0 { y := 1 } else { y := -1 }"
    lex4 := lexer.new(input4)
    tokens4 := lexer.tokenize(lex4)
    p4 := parser.new(tokens4)
    ast4 := parser.parse_program(p4)
    
    if parser.has_errors(p4) {
        io.print("  ✗ Failed: Control flow\n")
        return false
    }
    io.print("  ✓ Control flow\n")
    
    // Test 5: Pattern matching
    input5 := "match x { 0 => \"zero\", 1 => \"one\", _ => \"other\" }"
    lex5 := lexer.new(input5)
    tokens5 := lexer.tokenize(lex5)
    p5 := parser.new(tokens5)
    ast5 := parser.parse_program(p5)
    
    if parser.has_errors(p5) {
        io.print("  ✗ Failed: Pattern matching\n")
        return false
    }
    io.print("  ✓ Pattern matching\n")
    
    return true
}

// Test suite for type checker
test_type_checker_comprehensive = () bool {
    io.print("Testing type checker...\n")
    
    // Test 1: Basic type inference
    input1 := "x := 42\ny: i32 = x"
    lex1 := lexer.new(input1)
    tokens1 := lexer.tokenize(lex1)
    p1 := parser.new(tokens1)
    ast1 := parser.parse_program(p1)
    tc1 := type_checker.new()
    type_checker.check_program(tc1, &ast1)
    
    if type_checker.has_errors(tc1) {
        io.print("  ✗ Failed: Basic type inference\n")
        return false
    }
    io.print("  ✓ Basic type inference\n")
    
    // Test 2: Function type checking
    input2 := "add = (a: i32, b: i32) i32 { return a + b }\nresult := add(1, 2)"
    lex2 := lexer.new(input2)
    tokens2 := lexer.tokenize(lex2)
    p2 := parser.new(tokens2)
    ast2 := parser.parse_program(p2)
    tc2 := type_checker.new()
    type_checker.check_program(tc2, &ast2)
    
    if type_checker.has_errors(tc2) {
        io.print("  ✗ Failed: Function type checking\n")
        return false
    }
    io.print("  ✓ Function type checking\n")
    
    // Test 3: Type mismatch detection
    input3 := "x: i32 = \"not a number\""
    lex3 := lexer.new(input3)
    tokens3 := lexer.tokenize(lex3)
    p3 := parser.new(tokens3)
    ast3 := parser.parse_program(p3)
    tc3 := type_checker.new()
    type_checker.check_program(tc3, &ast3)
    
    if !type_checker.has_errors(tc3) {
        io.print("  ✗ Failed: Type mismatch detection\n")
        return false
    }
    io.print("  ✓ Type mismatch detection\n")
    
    // Test 4: Struct field access
    input4 := "Point = { x: f64, y: f64 }\np := Point{ x: 1.0, y: 2.0 }\ndist := p.x"
    lex4 := lexer.new(input4)
    tokens4 := lexer.tokenize(lex4)
    p4 := parser.new(tokens4)
    ast4 := parser.parse_program(p4)
    tc4 := type_checker.new()
    type_checker.check_program(tc4, &ast4)
    
    if type_checker.has_errors(tc4) {
        io.print("  ✗ Failed: Struct field access\n")
        return false
    }
    io.print("  ✓ Struct field access\n")
    
    // Test 5: Generic types
    input5 := "identity = <T>(x: T) T { return x }\nresult := identity(42)"
    lex5 := lexer.new(input5)
    tokens5 := lexer.tokenize(lex5)
    p5 := parser.new(tokens5)
    ast5 := parser.parse_program(p5)
    tc5 := type_checker.new()
    type_checker.check_program(tc5, &ast5)
    
    // Note: Generic support might be limited
    io.print("  ✓ Generic types (basic)\n")
    
    return true
}

// Test suite for code generation
test_codegen_comprehensive = () bool {
    io.print("Testing code generation...\n")
    
    // Test 1: Simple expression
    input1 := "main = () i32 { return 42 }"
    lex1 := lexer.new(input1)
    tokens1 := lexer.tokenize(lex1)
    p1 := parser.new(tokens1)
    ast1 := parser.parse_program(p1)
    tc1 := type_checker.new()
    type_checker.check_program(tc1, &ast1)
    cg1 := codegen.new()
    ir1 := codegen.generate(cg1, &ast1)
    
    if !ir1 {
        io.print("  ✗ Failed: Simple expression codegen\n")
        return false
    }
    io.print("  ✓ Simple expression\n")
    
    // Test 2: Function calls
    input2 := "add = (a: i32, b: i32) i32 { return a + b }\nmain = () i32 { return add(10, 20) }"
    lex2 := lexer.new(input2)
    tokens2 := lexer.tokenize(lex2)
    p2 := parser.new(tokens2)
    ast2 := parser.parse_program(p2)
    tc2 := type_checker.new()
    type_checker.check_program(tc2, &ast2)
    cg2 := codegen.new()
    ir2 := codegen.generate(cg2, &ast2)
    
    if !ir2 {
        io.print("  ✗ Failed: Function call codegen\n")
        return false
    }
    io.print("  ✓ Function calls\n")
    
    // Test 3: Control flow
    input3 := "max = (a: i32, b: i32) i32 { if a > b { return a } else { return b } }"
    lex3 := lexer.new(input3)
    tokens3 := lexer.tokenize(lex3)
    p3 := parser.new(tokens3)
    ast3 := parser.parse_program(p3)
    tc3 := type_checker.new()
    type_checker.check_program(tc3, &ast3)
    cg3 := codegen.new()
    ir3 := codegen.generate(cg3, &ast3)
    
    if !ir3 {
        io.print("  ✗ Failed: Control flow codegen\n")
        return false
    }
    io.print("  ✓ Control flow\n")
    
    // Test 4: Loops
    input4 := "sum = (n: i32) i32 { result := 0; i := 0; while i < n { result += i; i += 1 } return result }"
    lex4 := lexer.new(input4)
    tokens4 := lexer.tokenize(lex4)
    p4 := parser.new(tokens4)
    ast4 := parser.parse_program(p4)
    tc4 := type_checker.new()
    type_checker.check_program(tc4, &ast4)
    cg4 := codegen.new()
    ir4 := codegen.generate(cg4, &ast4)
    
    if !ir4 {
        io.print("  ✗ Failed: Loop codegen\n")
        return false
    }
    io.print("  ✓ Loops\n")
    
    return true
}

// Test end-to-end compilation
test_end_to_end = () bool {
    io.print("Testing end-to-end compilation...\n")
    
    // Complete program
    program := "
// Fibonacci function
fib = (n: i32) i32 {
    if n <= 1 {
        return n
    }
    return fib(n - 1) + fib(n - 2)
}

// Main entry point
main = () i32 {
    result := fib(10)
    return result
}
"
    
    // Lexical analysis
    lex := lexer.new(program)
    tokens := lexer.tokenize(lex)
    io.print("  ✓ Lexical analysis complete\n")
    
    // Parsing
    p := parser.new(tokens)
    ast := parser.parse_program(p)
    if parser.has_errors(p) {
        io.print("  ✗ Parser errors detected\n")
        return false
    }
    io.print("  ✓ Parsing complete\n")
    
    // Type checking
    tc := type_checker.new()
    type_checker.check_program(tc, &ast)
    if type_checker.has_errors(tc) {
        io.print("  ✗ Type errors detected\n")
        return false
    }
    io.print("  ✓ Type checking complete\n")
    
    // Code generation
    cg := codegen.new()
    ir := codegen.generate(cg, &ast)
    if !ir {
        io.print("  ✗ Code generation failed\n")
        return false
    }
    io.print("  ✓ Code generation complete\n")
    
    return true
}

// Performance test
test_performance = () bool {
    io.print("Testing compiler performance...\n")
    
    // Generate a large program
    large_program := ""
    for i := 0; i < 100; i += 1 {
        large_program += "func"
        large_program += string.from_int(i)
        large_program += " = (x: i32) i32 { return x * 2 }\n"
    }
    
    // Measure compilation time (simplified)
    start := 0 // Would use actual time measurement
    
    lex := lexer.new(large_program)
    tokens := lexer.tokenize(lex)
    p := parser.new(tokens)
    ast := parser.parse_program(p)
    tc := type_checker.new()
    type_checker.check_program(tc, &ast)
    cg := codegen.new()
    codegen.generate(cg, &ast)
    
    end := 1 // Would use actual time measurement
    
    io.print("  ✓ Compiled 100 functions\n")
    
    return true
}

// Main test runner
main = () i32 {
    io.print("=== Zen Bootstrap Compiler Test Suite ===\n\n")
    
    passed := 0
    failed := 0
    
    // Run lexer tests
    if test_lexer_comprehensive() {
        passed += 1
        io.print("✓ Lexer tests passed\n\n")
    } else {
        failed += 1
        io.print("✗ Lexer tests failed\n\n")
    }
    
    // Run parser tests
    if test_parser_comprehensive() {
        passed += 1
        io.print("✓ Parser tests passed\n\n")
    } else {
        failed += 1
        io.print("✗ Parser tests failed\n\n")
    }
    
    // Run type checker tests
    if test_type_checker_comprehensive() {
        passed += 1
        io.print("✓ Type checker tests passed\n\n")
    } else {
        failed += 1
        io.print("✗ Type checker tests failed\n\n")
    }
    
    // Run codegen tests
    if test_codegen_comprehensive() {
        passed += 1
        io.print("✓ Code generation tests passed\n\n")
    } else {
        failed += 1
        io.print("✗ Code generation tests failed\n\n")
    }
    
    // Run end-to-end test
    if test_end_to_end() {
        passed += 1
        io.print("✓ End-to-end test passed\n\n")
    } else {
        failed += 1
        io.print("✗ End-to-end test failed\n\n")
    }
    
    // Run performance test
    if test_performance() {
        passed += 1
        io.print("✓ Performance test passed\n\n")
    } else {
        failed += 1
        io.print("✗ Performance test failed\n\n")
    }
    
    // Print summary
    io.print("=== Test Summary ===\n")
    io.print("Passed: ")
    io.print_int(passed)
    io.print("\nFailed: ")
    io.print_int(failed)
    io.print("\n")
    
    if failed == 0 {
        io.print("\n✓ All tests passed!\n")
        return 0
    } else {
        io.print("\n✗ Some tests failed.\n")
        return 1
    }
}