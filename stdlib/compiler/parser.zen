// Zen Parser - Self-hosted parser implementation
// Enhanced version with proper AST structure

core := @std.core
io := @std.io
token := @compiler.token
lexer := @compiler.lexer

// AST Node Types
NodeType = enum {
    // Statements
    Program,
    FunctionDecl,
    VariableDecl,
    Assignment,
    Return,
    If,
    Loop,
    Break,
    Continue,
    Block,
    ExpressionStmt,
    
    // Expressions
    Binary,
    Unary,
    Literal,
    Identifier,
    FunctionCall,
    MemberAccess,
    ArrayAccess,
    StructLiteral,
    ArrayLiteral,
    PatternMatch,
}

// Type representation
Type = {
    name: String,
    is_pointer: bool,
    is_array: bool,
    array_size: i32,
}

// AST Node
AstNode = {
    type: NodeType,
    // Location info
    line: i32,
    column: i32,
    
    // Node-specific data (simplified union)
    // For literals
    int_value: i64,
    float_value: f64,
    string_value: String,
    bool_value: bool,
    
    // For identifiers and names
    name: String,
    
    // For binary/unary operations
    operator: String,
    left: *AstNode,
    right: *AstNode,
    operand: *AstNode,
    
    // For functions
    params: [*AstNode],
    return_type: *Type,
    body: *AstNode,
    
    // For blocks and programs
    statements: [*AstNode],
    
    // For variables
    var_type: *Type,
    initializer: *AstNode,
    is_mutable: bool,
    
    // For conditionals
    condition: *AstNode,
    then_branch: *AstNode,
    else_branch: *AstNode,
    
    // For pattern matching
    scrutinee: *AstNode,
    arms: [*MatchArm],
    
    // For function calls
    callee: *AstNode,
    arguments: [*AstNode],
}

// Pattern matching arm
MatchArm = {
    pattern: *Pattern,
    guard: *AstNode,  // Optional guard condition
    body: *AstNode,
}

// Pattern types
Pattern = {
    is_wildcard: bool,
    is_literal: bool,
    is_identifier: bool,
    is_struct: bool,
    
    // Pattern data
    literal_value: *AstNode,
    identifier_name: String,
    struct_name: String,
    struct_fields: [*Pattern],
}

// Parser state
Parser = {
    tokens: [token.Token],
    current: i32,
    errors: [String],
}

// Create a new parser
parser_new = (tokens: [token.Token]) Parser {
    return Parser {
        tokens: tokens,
        current: 0,
        errors: [],
    }
}

// Check if we're at the end
parser_is_at_end = (p: *Parser) bool {
    return p.current >= p.tokens.len() || 
           p.tokens[p.current].type == token.TokenType.EOF
}

// Peek at current token
parser_peek = (p: *Parser) token.Token {
    parser_is_at_end(p) ? | true => {
        // Return EOF token
        return token.create_token(token.TokenType.EOF, "", 0, 0)
    } | false => {
        return p.tokens[p.current]
    }
}

// Advance to next token
parser_advance = (p: *Parser) token.Token {
    !parser_is_at_end(p) ? | true => {
        p.current = p.current + 1
    } | false => {}
    return p.tokens[p.current - 1]
}

// Check if current token matches type
parser_check = (p: *Parser, type: token.TokenType) bool {
    parser_is_at_end(p) ? | true => { return false } | false => {}
    return parser_peek(p).type == type
}

// Match and consume token if it matches
parser_match = (p: *Parser, types: [token.TokenType]) bool {
    i := 0
    loop (i < types.len()) {
        parser_check(p, types[i]) ? | true => {
            parser_advance(p)
            return true
        } | false => {}
        i = i + 1
    }
    return false
}

// Consume token or error
parser_consume = (p: *Parser, type: token.TokenType, message: String) token.Token {
    parser_check(p, type) ? | true => {
        return parser_advance(p)
    } | false => {
        p.errors.append(message)
        // Return error token
        return token.create_token(token.TokenType.EOF, "ERROR", 0, 0)
    }
}

// Parse primary expression
parser_parse_primary = (p: *Parser) *AstNode {
    // Integer literal
    parser_match(p, [token.TokenType.Integer]) ? | true => {
        tok := p.tokens[p.current - 1]
        node := AstNode {
            type: NodeType.Literal,
            line: tok.line,
            column: tok.column,
            int_value: tok.value.to_int(),  // Assuming string to int conversion
        }
        return &node
    } | false => {}
    
    // Float literal
    parser_match(p, [token.TokenType.Float]) ? | true => {
        tok := p.tokens[p.current - 1]
        node := AstNode {
            type: NodeType.Literal,
            line: tok.line,
            column: tok.column,
            float_value: tok.value.to_float(),  // Assuming string to float conversion
        }
        return &node
    } | false => {}
    
    // String literal
    parser_match(p, [token.TokenType.String]) ? | true => {
        tok := p.tokens[p.current - 1]
        node := AstNode {
            type: NodeType.Literal,
            line: tok.line,
            column: tok.column,
            string_value: tok.value,
        }
        return &node
    } | false => {}
    
    // Boolean literals (true/false keywords)
    parser_peek(p).type == token.TokenType.Keyword && 
    (parser_peek(p).value == "true" || parser_peek(p).value == "false") ? | true => {
        tok := parser_advance(p)
        node := AstNode {
            type: NodeType.Literal,
            line: tok.line,
            column: tok.column,
            bool_value: tok.value == "true",
        }
        return &node
    } | false => {}
    
    // Identifier
    parser_match(p, [token.TokenType.Identifier]) ? | true => {
        tok := p.tokens[p.current - 1]
        node := AstNode {
            type: NodeType.Identifier,
            line: tok.line,
            column: tok.column,
            name: tok.value,
        }
        return &node
    } | false => {}
    
    // Parenthesized expression
    parser_match(p, [token.TokenType.LeftParen]) ? | true => {
        expr := parser_parse_expression(p)
        parser_consume(p, token.TokenType.RightParen, "Expected ')' after expression")
        return expr
    } | false => {}
    
    // If we get here, we have an error
    p.errors.append("Unexpected token in expression")
    return &AstNode { type = NodeType.Literal }  // Return error node
}

// Parse expression (simplified for now)
parser_parse_expression = (p: *Parser) *AstNode {
    return parser_parse_equality(p)
}

// Parse equality operators
parser_parse_equality = (p: *Parser) *AstNode {
    expr := parser_parse_comparison(p)
    
    loop (parser_match(p, [token.TokenType.Equals, token.TokenType.NotEquals])) {
        op := p.tokens[p.current - 1]
        right := parser_parse_comparison(p)
        
        binary_node := AstNode {
            type: NodeType.Binary,
            line: op.line,
            column: op.column,
            operator: op.value,
            left: expr,
            right: right,
        }
        expr = &binary_node
    }
    
    return expr
}

// Parse comparison operators
parser_parse_comparison = (p: *Parser) *AstNode {
    expr := parser_parse_addition(p)
    
    loop (parser_match(p, [token.TokenType.LessThan, token.TokenType.LessThanEquals,
                           token.TokenType.GreaterThan, token.TokenType.GreaterThanEquals])) {
        op := p.tokens[p.current - 1]
        right := parser_parse_addition(p)
        
        binary_node := AstNode {
            type: NodeType.Binary,
            line: op.line,
            column: op.column,
            operator: op.value,
            left: expr,
            right: right,
        }
        expr = &binary_node
    }
    
    return expr
}

// Parse addition/subtraction
parser_parse_addition = (p: *Parser) *AstNode {
    expr := parser_parse_multiplication(p)
    
    loop (parser_match(p, [token.TokenType.Plus, token.TokenType.Minus])) {
        op := p.tokens[p.current - 1]
        right := parser_parse_multiplication(p)
        
        binary_node := AstNode {
            type: NodeType.Binary,
            line: op.line,
            column: op.column,
            operator: op.value,
            left: expr,
            right: right,
        }
        expr = &binary_node
    }
    
    return expr
}

// Parse multiplication/division
parser_parse_multiplication = (p: *Parser) *AstNode {
    expr := parser_parse_unary(p)
    
    loop (parser_match(p, [token.TokenType.Star, token.TokenType.Slash, token.TokenType.Percent])) {
        op := p.tokens[p.current - 1]
        right := parser_parse_unary(p)
        
        binary_node := AstNode {
            type: NodeType.Binary,
            line: op.line,
            column: op.column,
            operator: op.value,
            left: expr,
            right: right,
        }
        expr = &binary_node
    }
    
    return expr
}

// Parse unary operators
parser_parse_unary = (p: *Parser) *AstNode {
    parser_match(p, [token.TokenType.Not, token.TokenType.Minus]) ? | true => {
        op := p.tokens[p.current - 1]
        operand := parser_parse_unary(p)
        
        unary_node := AstNode {
            type: NodeType.Unary,
            line: op.line,
            column: op.column,
            operator: op.value,
            operand: operand,
        }
        return &unary_node
    } | false => {}
    
    return parser_parse_postfix(p)
}

// Parse postfix operations (function calls, member access, array access)
parser_parse_postfix = (p: *Parser) *AstNode {
    expr := parser_parse_primary(p)
    
    loop {
        // Function call
        parser_match(p, [token.TokenType.LeftParen]) ? | true => {
            args := []
            
            !parser_check(p, token.TokenType.RightParen) ? | true => {
                loop {
                    args.append(parser_parse_expression(p))
                    !parser_match(p, [token.TokenType.Comma]) ? | true => { break } | false => {}
                }
            } | false => {}
            
            parser_consume(p, token.TokenType.RightParen, "Expected ')' after arguments")
            
            call_node := AstNode {
                type: NodeType.FunctionCall,
                line: expr.line,
                column: expr.column,
                callee: expr,
                arguments: args,
            }
            expr = &call_node
            continue
        } | false => {}
        
        // Member access
        parser_match(p, [token.TokenType.Dot]) ? | true => {
            member := parser_consume(p, token.TokenType.Identifier, "Expected member name after '.'")
            
            access_node := AstNode {
                type: NodeType.MemberAccess,
                line: member.line,
                column: member.column,
                left: expr,
                name: member.value,
            }
            expr = &access_node
            continue
        } | false => {}
        
        // Array access
        parser_match(p, [token.TokenType.LeftBracket]) ? | true => {
            index := parser_parse_expression(p)
            parser_consume(p, token.TokenType.RightBracket, "Expected ']' after array index")
            
            array_node := AstNode {
                type: NodeType.ArrayAccess,
                line: expr.line,
                column: expr.column,
                left: expr,
                right: index,
            }
            expr = &array_node
            continue
        } | false => {}
        
        break
    }
    
    return expr
}

// Parse statement
parser_parse_statement = (p: *Parser) *AstNode {
    // Function declaration
    parser_peek(p).type == token.TokenType.Identifier ? | true => {
        // Check if this is a function declaration (name = (...) ...)
        curr_pos := p.current
        name_tok := parser_advance(p)
        
        parser_match(p, [token.TokenType.Assign]) ? | true => {
            parser_match(p, [token.TokenType.LeftParen]) ? | true => {
                // This is a function declaration
                return parser_parse_function_decl(p, name_tok)
            } | false => {
                // Regular assignment, restore position
                p.current = curr_pos
            }
        } | false => {
            // Check for variable declaration with :=
            p.current = curr_pos
            next_tok := p.tokens[p.current + 1]
            
            next_tok.type == token.TokenType.AssignConst ? | true => {
                // Variable declaration
                name_tok := parser_advance(p)
                parser_advance(p)  // consume :=
                init := parser_parse_expression(p)
                
                var_node := AstNode {
                    type: NodeType.VariableDecl,
                    line: name_tok.line,
                    column: name_tok.column,
                    name: name_tok.value,
                    initializer: init,
                    is_mutable: false,
                }
                return &var_node
            } | false => {
                p.current = curr_pos
            }
        }
    } | false => {}
    
    // If statement
    parser_peek(p).type == token.TokenType.Keyword && 
    parser_peek(p).value == "if" ? | true => {
        return parser_parse_if_statement(p)
    } | false => {}
    
    // Loop statement
    parser_peek(p).type == token.TokenType.Keyword && 
    parser_peek(p).value == "loop" ? | true => {
        return parser_parse_loop_statement(p)
    } | false => {}
    
    // Return statement
    parser_peek(p).type == token.TokenType.Keyword && 
    parser_peek(p).value == "return" ? | true => {
        ret_tok := parser_advance(p)
        
        // Optional return value
        value := parser_is_at_end(p) || parser_peek(p).value == "}" ? 
            | true => { nullptr } 
            | false => { parser_parse_expression(p) }
        
        ret_node := AstNode {
            type: NodeType.Return,
            line: ret_tok.line,
            column: ret_tok.column,
            operand: value,
        }
        return &ret_node
    } | false => {}
    
    // Break statement
    parser_peek(p).type == token.TokenType.Keyword && 
    parser_peek(p).value == "break" ? | true => {
        tok := parser_advance(p)
        break_node := AstNode {
            type: NodeType.Break,
            line: tok.line,
            column: tok.column,
        }
        return &break_node
    } | false => {}
    
    // Continue statement
    parser_peek(p).type == token.TokenType.Keyword && 
    parser_peek(p).value == "continue" ? | true => {
        tok := parser_advance(p)
        continue_node := AstNode {
            type: NodeType.Continue,
            line: tok.line,
            column: tok.column,
        }
        return &continue_node
    } | false => {}
    
    // Expression statement
    expr := parser_parse_expression(p)
    expr_stmt := AstNode {
        type: NodeType.ExpressionStmt,
        line: expr.line,
        column: expr.column,
        operand: expr,
    }
    return &expr_stmt
}

// Parse function declaration
parser_parse_function_decl = (p: *Parser, name_tok: token.Token) *AstNode {
    // Parse parameters
    params := []
    !parser_check(p, token.TokenType.RightParen) ? | true => {
        loop {
            param_name := parser_consume(p, token.TokenType.Identifier, "Expected parameter name")
            parser_consume(p, token.TokenType.Colon, "Expected ':' after parameter name")
            
            // Parse type (simplified for now)
            type_tok := parser_consume(p, token.TokenType.Identifier, "Expected type name")
            
            param_node := AstNode {
                type: NodeType.VariableDecl,
                line: param_name.line,
                column: param_name.column,
                name: param_name.value,
                var_type: &Type { name: type_tok.value },
            }
            params.append(&param_node)
            
            !parser_match(p, [token.TokenType.Comma]) ? | true => { break } | false => {}
        }
    } | false => {}
    
    parser_consume(p, token.TokenType.RightParen, "Expected ')' after parameters")
    
    // Parse return type
    mut return_type := &Type { name: "void" }
    !parser_match(p, [token.TokenType.LeftBrace]) ? | true => {
        type_tok := parser_consume(p, token.TokenType.Identifier, "Expected return type")
        return_type = &Type { name: type_tok.value }
        parser_consume(p, token.TokenType.LeftBrace, "Expected '{' before function body")
    } | false => {}
    
    // Parse function body
    body := parser_parse_block(p)
    
    func_node := AstNode {
        type: NodeType.FunctionDecl,
        line: name_tok.line,
        column: name_tok.column,
        name: name_tok.value,
        params: params,
        return_type: return_type,
        body: body,
    }
    
    return &func_node
}

// Parse if statement
parser_parse_if_statement = (p: *Parser) *AstNode {
    if_tok := parser_advance(p)  // consume 'if'
    
    // Parse condition (could be expression or pattern match)
    condition := parser_parse_expression(p)
    
    // Check for pattern match syntax
    parser_match(p, [token.TokenType.Question]) ? | true => {
        parser_consume(p, token.TokenType.Pipe, "Expected '|' after '?'")
        
        // Parse match arms
        arms := []
        loop {
            // Parse pattern (simplified - just true/false for now)
            pattern_tok := parser_consume(p, token.TokenType.Identifier, "Expected pattern")
            
            pattern := Pattern {
                is_literal: true,
                identifier_name: pattern_tok.value,
            }
            
            parser_consume(p, token.TokenType.Arrow, "Expected '=>' after pattern")
            
            // Parse arm body
            body := parser_parse_block(p)
            
            arm := MatchArm {
                pattern: &pattern,
                body: body,
            }
            arms.append(&arm)
            
            parser_match(p, [token.TokenType.Pipe]) ? | false => { break } | true => {}
        }
        
        match_node := AstNode {
            type: NodeType.PatternMatch,
            line: if_tok.line,
            column: if_tok.column,
            scrutinee: condition,
            arms: arms,
        }
        return &match_node
    } | false => {
        // Regular if-else
        parser_consume(p, token.TokenType.LeftBrace, "Expected '{' after if condition")
        then_branch := parser_parse_block(p)
        
        mut else_branch := nullptr
        parser_peek(p).type == token.TokenType.Keyword && 
        parser_peek(p).value == "else" ? | true => {
            parser_advance(p)  // consume 'else'
            parser_consume(p, token.TokenType.LeftBrace, "Expected '{' after else")
            else_branch = parser_parse_block(p)
        } | false => {}
        
        if_node := AstNode {
            type: NodeType.If,
            line: if_tok.line,
            column: if_tok.column,
            condition: condition,
            then_branch: then_branch,
            else_branch: else_branch,
        }
        return &if_node
    }
}

// Parse loop statement
parser_parse_loop_statement = (p: *Parser) *AstNode {
    loop_tok := parser_advance(p)  // consume 'loop'
    
    // Check for loop condition
    mut condition := nullptr
    parser_match(p, [token.TokenType.LeftParen]) ? | true => {
        condition = parser_parse_expression(p)
        parser_consume(p, token.TokenType.RightParen, "Expected ')' after loop condition")
    } | false => {}
    
    parser_consume(p, token.TokenType.LeftBrace, "Expected '{' after loop")
    body := parser_parse_block(p)
    
    loop_node := AstNode {
        type: NodeType.Loop,
        line: loop_tok.line,
        column: loop_tok.column,
        condition: condition,
        body: body,
    }
    
    return &loop_node
}

// Parse block of statements
parser_parse_block = (p: *Parser) *AstNode {
    statements := []
    
    loop (!parser_check(p, token.TokenType.RightBrace) && !parser_is_at_end(p)) {
        stmt := parser_parse_statement(p)
        statements.append(stmt)
        
        // Optional semicolon
        parser_match(p, [token.TokenType.Semicolon])
    }
    
    parser_consume(p, token.TokenType.RightBrace, "Expected '}' after block")
    
    block_node := AstNode {
        type: NodeType.Block,
        line: 0,
        column: 0,
        statements: statements,
    }
    
    return &block_node
}

// Parse program
parser_parse_program = (p: *Parser) *AstNode {
    statements := []
    
    loop (!parser_is_at_end(p)) {
        stmt := parser_parse_statement(p)
        statements.append(stmt)
        
        // Optional semicolon
        parser_match(p, [token.TokenType.Semicolon])
    }
    
    program := AstNode {
        type: NodeType.Program,
        line: 0,
        column: 0,
        statements: statements,
    }
    
    return &program
}

// Main test function
main = () i32 {
    io.print("Zen Parser - Self-hosting component\n")
    io.print("===================================\n\n")
    
    // Test input
    input := "x := 42\ny := x + 10 * 2\nreturn y"
    io.print("Input:\n")
    io.print(input)
    io.print("\n\n")
    
    // Tokenize
    l := lexer.lexer_new(input)
    tokens := []
    loop {
        tok := lexer.lexer_next_token(&l)
        tokens.append(tok)
        tok.type == token.TokenType.EOF ? | true => { break } | false => {}
    }
    
    // Parse
    p := parser_new(tokens)
    ast := parser_parse_program(&p)
    
    // Report results
    io.print("Parsing complete!\n")
    io.print("Statements parsed: ")
    io.print_int(ast.statements.len())
    io.print("\n")
    
    p.errors.len() > 0 ? | true => {
        io.print("\nErrors:\n")
        i := 0
        loop (i < p.errors.len()) {
            io.print("  - ")
            io.print(p.errors[i])
            io.print("\n")
            i = i + 1
        }
    } | false => {
        io.print("No errors!\n")
    }
    
    return 0
}