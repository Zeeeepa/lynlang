// Unit Testing Framework for Zen

io = @std
string = @std
vec = @std
core = @std
time = @std

// Test result types
TestResult: Pass
    | Fail(string)
    | Skip(string)
    | Error(string)

// Test case structure
TestCase: {
    name: string,
    test_fn: () TestResult,
    file: string,
    line: u32,
}

// Test suite structure
TestSuite: {
    name: string,
    tests: Vec<TestCase>,
    setup: Option<() void>,
    teardown: Option<() void>,
}

// Test runner statistics
TestStats: {
    total: u32,
    passed: u32,
    failed: u32,
    skipped: u32,
    errors: u32,
    duration_ms: u64,
}

// Global test registry
TEST_REGISTRY := vec.new<TestSuite>()

// Colors for terminal output
COLOR_GREEN := "\x1b[32m"
COLOR_RED := "\x1b[31m"
COLOR_YELLOW := "\x1b[33m"
COLOR_BLUE := "\x1b[34m"
COLOR_RESET := "\x1b[0m"

// Create a new test suite
suite = (name: string) TestSuite   {
    return TestSuite {
        name: name,
        tests: vec.new<TestCase>(),
        setup: Option.None,
        teardown: Option.None,
    }
}

// Add setup function to suite
suite_setup = (s: MutPtr<TestSuite>, setup_fn: () void) void {
    s.setup = Option.Some(setup_fn)
}

// Add teardown function to suite
suite_teardown = (s: MutPtr<TestSuite>, teardown_fn: () void) void {
    s.teardown = Option.Some(teardown_fn)
}

// Add test case to suite
add_test = (s: MutPtr<TestSuite>, name: string, test_fn: () TestResult) void {
    test_case := TestCase {
        name: name,
        test_fn: test_fn,
        file: __FILE__,
        line: __LINE__,
    }
    vec.push(&s.tests, test_case)
}

// Register suite with global registry
register_suite = (s: TestSuite) void   {
    vec.push(&TEST_REGISTRY, s)
}

// Assertion functions
assert = (condition: bool) TestResult   {
    if condition {
        return TestResult.Pass
    }
    return TestResult.Fail("Assertion failed")
}

assert_with_msg = (condition: bool, msg: string) TestResult   {
    if condition {
        return TestResult.Pass
    }
    return TestResult.Fail(msg)
}

assert_eq = <T>(actual: T, expected: T) TestResult {
    if actual == expected {
        return TestResult.Pass
    }
    msg := string.format("Expected: {}, Got: {}", expected, actual)
    return TestResult.Fail(msg)
}

assert_ne = <T>(actual: T, not_expected: T) TestResult {
    if actual != not_expected {
        return TestResult.Pass
    }
    msg := string.format("Expected not equal to: {}, Got: {}", not_expected, actual)
    return TestResult.Fail(msg)
}

assert_lt = <T>(actual: T, limit: T) TestResult {
    if actual < limit {
        return TestResult.Pass
    }
    msg := string.format("Expected {} < {}", actual, limit)
    return TestResult.Fail(msg)
}

assert_le = <T>(actual: T, limit: T) TestResult {
    if actual <= limit {
        return TestResult.Pass
    }
    msg := string.format("Expected {} <= {}", actual, limit)
    return TestResult.Fail(msg)
}

assert_gt = <T>(actual: T, limit: T) TestResult {
    if actual > limit {
        return TestResult.Pass
    }
    msg := string.format("Expected {} > {}", actual, limit)
    return TestResult.Fail(msg)
}

assert_ge = <T>(actual: T, limit: T) TestResult {
    if actual >= limit {
        return TestResult.Pass
    }
    msg := string.format("Expected {} >= {}", actual, limit)
    return TestResult.Fail(msg)
}

assert_true = (value: bool) TestResult   {
    if value {
        return TestResult.Pass
    }
    return TestResult.Fail("Expected true, got false")
}

assert_false = (value: bool) TestResult   {
    if !value {
        return TestResult.Pass
    }
    return TestResult.Fail("Expected false, got true")
}

assert_nil = <T>(value: Option<T>) TestResult {
    if value .== None {
        return TestResult.Pass
    }
    return TestResult.Fail("Expected nil value")
}

assert_not_nil = <T>(value: Option<T>) TestResult {
    if value != null {
        return TestResult.Pass
    }
    return TestResult.Fail("Expected non-nil value")
}

assert_contains = (haystack: string, needle: string) TestResult   {
    if string.contains(haystack, needle) {
        return TestResult.Pass
    }
    msg := string.format("Expected '{}' to contain '{}'", haystack, needle)
    return TestResult.Fail(msg)
}

assert_starts_with = (str: string, prefix: string) TestResult   {
    if string.starts_with(str, prefix) {
        return TestResult.Pass
    }
    msg := string.format("Expected '{}' to start with '{}'", str, prefix)
    return TestResult.Fail(msg)
}

assert_ends_with = (str: string, suffix: string) TestResult   {
    if string.ends_with(str, suffix) {
        return TestResult.Pass
    }
    msg := string.format("Expected '{}' to end with '{}'", str, suffix)
    return TestResult.Fail(msg)
}

// Float comparison with epsilon
assert_float_eq = (actual: f64, expected: f64, epsilon: f64) TestResult   {
    diff := if actual > expected { actual - expected } else { expected - actual }
    if diff <= epsilon {
        return TestResult.Pass
    }
    msg := string.format("Expected: {} ± {}, Got: {}", expected, epsilon, actual)
    return TestResult.Fail(msg)
}

// Array/slice comparison
assert_array_eq = <T>(actual: Vec<T>, expected: Vec<T>) TestResult {
    if actual.len != expected.len {
        msg := string.format("Array length mismatch. Expected: {}, Got: {}", expected.len, actual.len)
        return TestResult.Fail(msg)
    }
    
    for i := 0; i < actual.len; i += 1 {
        if actual[i] != expected[i] {
            msg := string.format("Array mismatch at index {}. Expected: {}, Got: {}", 
                                i, expected[i], actual[i])
            return TestResult.Fail(msg)
        }
    }
    
    return TestResult.Pass
}

// Skip test with reason
skip = (reason: string) TestResult   {
    return TestResult.Skip(reason)
}

// Mark test as error
error = (msg: string) TestResult   {
    return TestResult.Error(msg)
}

// Run a single test case
run_test = (test: &TestCase) TestResult   {
    // TODO: Add timeout and panic recovery
    return test.test_fn()
}

// Run a test suite
run_suite = (suite: &TestSuite) TestStats   {
    stats := TestStats {
        total: suite.tests.len as u32,
        passed: 0,
        failed: 0,
        skipped: 0,
        errors: 0,
        duration_ms: 0,
    }
    
    io.printf("\n{}Running suite: {}{}\n", COLOR_BLUE, suite.name, COLOR_RESET)
    io.println(string.repeat("-", 60))
    
    start_time := time.now_ms()
    
    // Run setup if provided
    if suite.setup.is_some() {
        suite.setup.unwrap()()
    }
    
    // Run each test
    for test in suite.tests {
        io.printf("  {} ... ", test.name)
        
        test_start := time.now_ms()
        result := run_test(&test)
        test_duration := time.now_ms() - test_start
        
        result ?
            TestResult.Pass => {
                io.printf("{}PASS{} ({}ms)\n", COLOR_GREEN, COLOR_RESET, test_duration)
                stats.passed += 1
            },
            TestResult.Fail(msg) => {
                io.printf("{}FAIL{}\n", COLOR_RED, COLOR_RESET)
                io.printf("    {}: {}\n", test.file, test.line)
                io.printf("    {}\n", msg)
                stats.failed += 1
            },
            TestResult.Skip(reason) => {
                io.printf("{}SKIP{} - {}\n", COLOR_YELLOW, COLOR_RESET, reason)
                stats.skipped += 1
            },
            TestResult.Error(msg) => {
                io.printf("{}ERROR{}\n", COLOR_RED, COLOR_RESET)
                io.printf("    {}\n", msg)
                stats.errors += 1
            }
        }
    }
    
    // Run teardown if provided
    if suite.teardown.is_some() {
        suite.teardown.unwrap()()
    }
    
    stats.duration_ms = time.now_ms() - start_time
    
    return stats
}

// Run all registered test suites
run_all = () TestStats   {
    total_stats := TestStats {
        total: 0,
        passed: 0,
        failed: 0,
        skipped: 0,
        errors: 0,
        duration_ms: 0,
    }
    
    io.println("\n╔════════════════════════════════════════╗")
    io.println("║         ZEN TEST RUNNER v1.0          ║")
    io.println("╚════════════════════════════════════════╝")
    
    start_time := time.now_ms()
    
    for suite in TEST_REGISTRY {
        stats := run_suite(&suite)
        total_stats.total += stats.total
        total_stats.passed += stats.passed
        total_stats.failed += stats.failed
        total_stats.skipped += stats.skipped
        total_stats.errors += stats.errors
    }
    
    total_stats.duration_ms = time.now_ms() - start_time
    
    // Print summary
    io.println("\n" + string.repeat("=", 60))
    io.println("TEST SUMMARY")
    io.println(string.repeat("=", 60))
    
    io.printf("Total:   {}\n", total_stats.total)
    io.printf("{}Passed:  {}{}\n", COLOR_GREEN, total_stats.passed, COLOR_RESET)
    
    if total_stats.failed > 0 {
        io.printf("{}Failed:  {}{}\n", COLOR_RED, total_stats.failed, COLOR_RESET)
    }
    
    if total_stats.skipped > 0 {
        io.printf("{}Skipped: {}{}\n", COLOR_YELLOW, total_stats.skipped, COLOR_RESET)
    }
    
    if total_stats.errors > 0 {
        io.printf("{}Errors:  {}{}\n", COLOR_RED, total_stats.errors, COLOR_RESET)
    }
    
    io.printf("Duration: {}ms\n", total_stats.duration_ms)
    
    // Overall result
    if total_stats.failed == 0 && total_stats.errors == 0 {
        io.printf("\n{}✓ All tests passed!{}\n", COLOR_GREEN, COLOR_RESET)
    } | false {
        io.printf("\n{}✗ Some tests failed{}\n", COLOR_RED, COLOR_RESET)
    }
    
    return total_stats
}

// Macro-like function for defining test suites
define_tests = (name: string, tests_fn: (MutPtr<TestSuite>) void) void {
    s := suite(name)
    tests_fn(&s)
    register_suite(s)
}

// Benchmark support
Benchmark: {
    name: string,
    iterations: u32,
    warmup: u32,
    fn: () void,
}

// Run benchmark
bench = (b: &Benchmark) void   {
    io.printf("Benchmarking {}: ", b.name)
    
    // Warmup
    for i := 0; i < b.warmup; i += 1 {
        b.fn()
    }
    
    // Actual benchmark
    start := time.now_ns()
    for i := 0; i < b.iterations; i += 1 {
        b.fn()
    }
    elapsed := time.now_ns() - start
    
    avg_ns := elapsed / b.iterations as u64
    io.printf("{} iterations in {}ms (avg: {}ns/op)\n", 
              b.iterations, elapsed / 1_000_000, avg_ns)
}

// Test helper to check if function panics
assert_panics = (fn: () void) TestResult {
    // TODO: Implement panic recovery mechanism
    // For now, this is a placeholder
    return TestResult.Skip("Panic testing not yet implemented")
}

// Test helper for concurrent functions using allocators
assert_concurrent = (fn: (*Allocator) TestResult, alloc: *Allocator) TestResult {
    // Use the provided allocator to determine execution mode
    return fn(alloc)
}