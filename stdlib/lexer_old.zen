// Zen Lexer - Self-hosted lexer implementation
// Complete implementation for bootstrapping the Zen compiler

comptime {
    core := @std.core
    string := @std.string
}

// Token types - matches the Rust implementation
TokenType = 
    | Identifier(value: string)
    | Integer(value: string)
    | Float(value: string)
    | StringLiteral(value: string)
    | Keyword(word: KeywordType)
    | Symbol(char: i8)
    | Operator(op: string)
    | Comment(text: string)
    | Eof

KeywordType = 
    | Loop
    | In
    | Comptime
    | Async
    | Await
    | Behavior
    | Impl
    | Extern
    | Break
    | Continue
    | Return
    | Type
    | Void
    | True
    | False

// Token with position information
Token = {
    token_type: TokenType,
    line: i32,
    column: i32,
    start: i32,
    end: i32,
}

// Lexer state
Lexer = {
    input: string,
    position: i32,
    read_position: i32,
    current_char: i8,  // Using i8 for char, -1 for EOF
    line: i32,
    column: i32,
}

// Create a new lexer
lexer_new = (input: string) Lexer {
    lexer := Lexer {
        input: input,
        position: 0,
        read_position: 0,
        current_char: 0,
        line: 1,
        column: 1,
    }
    
    // Read the first character
    lexer = lexer_read_char(lexer)
    return lexer
}

// Read next character
lexer_read_char = (l: Lexer) Lexer {
    l.position = l.read_position
    
    // Check if at end of input
    l.read_position >= string_len(l.input) ? 
        | true => {
            l.current_char = -1  // EOF marker
        }
        | false => {
            l.current_char = string_char_at(l.input, l.read_position)
            l.read_position = l.read_position + 1
            
            // Update line and column
            l.current_char == 10 ?  // '\n'
                | true => {
                    l.line = l.line + 1
                    l.column = 1
                }
                | false => {
                    l.column = l.column + 1
                }
        }
    
    return l
}

// Peek at next character without advancing
lexer_peek_char = (l: Lexer) i8 {
    l.read_position >= string_len(l.input) ?
        | true => return -1
        | false => return string_char_at(l.input, l.read_position)
}

// Peek two characters ahead
lexer_peek_char2 = (l: Lexer) i8 {
    pos := l.read_position + 1
    pos >= string_len(l.input) ?
        | true => return -1
        | false => return string_char_at(l.input, pos)
}

// Skip whitespace
lexer_skip_whitespace = (l: Lexer) Lexer {
    // Check if whitespace: space (32), tab (9), newline (10), carriage return (13)
    loop l.current_char == 32 || l.current_char == 9 || l.current_char == 10 || l.current_char == 13 {
        l = lexer_read_char(l)
    }
    return l
}

// Result type for functions that return Lexer and string
LexerStringResult = {
    lexer: Lexer,
    str: string,
}

// Skip single-line comment
lexer_skip_line_comment = (l: Lexer) LexerStringResult {
    start := l.position + 2  // Skip "//"
    l = lexer_read_char(l)  // Skip first /
    l = lexer_read_char(l)  // Skip second /
    
    loop l.current_char != 10 && l.current_char != -1 {
        l = lexer_read_char(l)
    }
    
    comment := string_substring(l.input, start, l.position)
    return LexerStringResult { lexer: l, str: comment }
}

// Skip multi-line comment
lexer_skip_block_comment = (l: Lexer) LexerStringResult {
    start := l.position + 2  // Skip "/*"
    l = lexer_read_char(l)  // Skip /
    l = lexer_read_char(l)  // Skip *
    
    loop l.current_char != -1 {
        l.current_char == 42 && lexer_peek_char(l) == 47 ?  // "*/"
            | true => {
                l = lexer_read_char(l)  // Skip *
                l = lexer_read_char(l)  // Skip /
                break
            }
            | false => {
                l = lexer_read_char(l)
            }
    }
    
    end := l.position - 2  // Exclude "*/"
    comment := string_substring(l.input, start, end)
    return LexerStringResult { lexer: l, str: comment }
}

// Character classification functions
is_whitespace = (c: i8) bool {
    c == 32 || c == 9 || c == 10 || c == 13  // space, tab, newline, carriage return
}

is_alpha = (c: i8) bool {
    (c >= 65 && c <= 90) || (c >= 97 && c <= 122) || c == 95  // A-Z, a-z, _
}

is_digit = (c: i8) bool {
    c >= 48 && c <= 57  // 0-9
}

is_hex_digit = (c: i8) bool {
    is_digit(c) || (c >= 65 && c <= 70) || (c >= 97 && c <= 102)  // 0-9, A-F, a-f
}

is_symbol = (c: i8) bool {
    c == 40 || c == 41 ||  // ( )
    c == 123 || c == 125 || // { }
    c == 91 || c == 93 ||   // [ ]
    c == 59 || c == 44 ||   // ; ,
    c == 124 || c == 38 ||  // | &
    c == 46 || c == 63      // . ?
}

is_operator_char = (c: i8) bool {
    c == 43 || c == 45 || c == 42 || c == 47 ||  // + - * /
    c == 61 || c == 33 || c == 60 || c == 62 ||  // = ! < >
    c == 38 || c == 124 || c == 58               // & | :
}

// Read identifier or keyword
lexer_read_identifier = (l: Lexer) LexerStringResult {
    start_pos := l.position
    
    // Handle @ prefix for namespaces
    l.current_char == 64 ?  // '@'
        | true => { l = lexer_read_char(l) }
        | false => {}
    
    // Read identifier characters (A-Z, a-z, _, 0-9)
    loop {
        is_id_char := (l.current_char >= 65 && l.current_char <= 90) || // A-Z
                      (l.current_char >= 97 && l.current_char <= 122) || // a-z
                      l.current_char == 95 || // _
                      (l.current_char >= 48 && l.current_char <= 57)  // 0-9
        
        is_id_char ? | false => break | true => {}
        l = lexer_read_char(l)
    }
    
    // Handle dot for namespace paths (e.g., @std.core)
    loop {
        l.current_char != 46 ? | true => break | false => {} // not '.'
        
        next := lexer_peek_char(l)
        is_next_alpha := (next >= 65 && next <= 90) || // A-Z
                        (next >= 97 && next <= 122) || // a-z
                        next == 95  // _
        
        is_next_alpha ? | false => break | true => {}
        
        l = lexer_read_char(l)  // consume '.'
        
        // Read the next identifier part
        loop {
            is_id_char := (l.current_char >= 65 && l.current_char <= 90) || // A-Z
                          (l.current_char >= 97 && l.current_char <= 122) || // a-z
                          l.current_char == 95 || // _
                          (l.current_char >= 48 && l.current_char <= 57)  // 0-9
            
            is_id_char ? | false => break | true => {}
            l = lexer_read_char(l)
        }
    }
    
    ident := string_substring(l.input, start_pos, l.position)
    return LexerStringResult { lexer: l, str: ident }
}

// Result type for number reading
LexerNumberResult = {
    lexer: Lexer,
    str: string,
    is_float: bool,
}

// Read number (integer or float)
lexer_read_number = (l: Lexer) LexerNumberResult {
    start_pos := l.position
    is_float := false
    
    // Handle hex numbers
    l.current_char == 48 && (lexer_peek_char(l) == 120 || lexer_peek_char(l) == 88) ?  // "0x" or "0X"
        | true => {
            l = lexer_read_char(l)  // consume '0'
            l = lexer_read_char(l)  // consume 'x'
            // Read hex digits (0-9, A-F, a-f)
            loop (l.current_char >= 48 && l.current_char <= 57) || (l.current_char >= 65 && l.current_char <= 70) || (l.current_char >= 97 && l.current_char <= 102) {
                l = lexer_read_char(l)
            }
        }
        | false => {
            // Regular decimal number
            // Read decimal digits
            loop l.current_char >= 48 && l.current_char <= 57 {
                l = lexer_read_char(l)
            }
            
            // Check for decimal point
            // Check if decimal point followed by digit
            next_char := lexer_peek_char(l)
            l.current_char == 46 && (next_char >= 48 && next_char <= 57) ?  // '.'
                | true => {
                    is_float = true
                    l = lexer_read_char(l)  // consume '.'
                    // Read decimal digits
            loop l.current_char >= 48 && l.current_char <= 57 {
                        l = lexer_read_char(l)
                    }
                    
                    // Handle scientific notation
                    (l.current_char == 101 || l.current_char == 69) ?  // 'e' or 'E'
                        | true => {
                            l = lexer_read_char(l)  // consume 'e'
                            (l.current_char == 43 || l.current_char == 45) ?  // '+' or '-'
                                | true => { l = lexer_read_char(l) }
                                | false => {}
                            // Read decimal digits
            loop l.current_char >= 48 && l.current_char <= 57 {
                                l = lexer_read_char(l)
                            }
                        }
                        | false => {}
                }
                | false => {}
        }
    
    // Handle type suffixes (i8, i16, i32, i64, u8, u16, u32, u64, f32, f64)
    (l.current_char == 105 || l.current_char == 117 || l.current_char == 102) ?  // 'i', 'u', 'f'
        | true => {
            // Read type suffix characters
            loop (l.current_char >= 65 && l.current_char <= 90) || (l.current_char >= 97 && l.current_char <= 122) || l.current_char == 95 || (l.current_char >= 48 && l.current_char <= 57) {
                l = lexer_read_char(l)
            }
        }
        | false => {}
    
    num := string_substring(l.input, start_pos, l.position)
    return LexerNumberResult { lexer: l, str: num, is_float: is_float }
}

// Read string literal with escape sequences
lexer_read_string = (l: Lexer) LexerStringResult {
    l = lexer_read_char(l)  // Skip opening quote
    start_pos := l.position
    
    loop l.current_char != 34 && l.current_char != -1 {  // '"'
        // Handle escape sequences
        l.current_char == 92 ?  // '\'
            | true => {
                l = lexer_read_char(l)  // Skip backslash
                l.current_char != -1 ?
                    | true => { l = lexer_read_char(l) }  // Skip escaped char
                    | false => {}
            }
            | false => {
                l = lexer_read_char(l)
            }
    }
    
    str := string_substring(l.input, start_pos, l.position)
    l.current_char == 34 ?
        | true => { l = lexer_read_char(l) }  // Skip closing quote
        | false => {}
    
    return LexerStringResult { lexer: l, str: str }
}

// Read operator (handles multi-character operators)
lexer_read_operator = (l: Lexer) LexerStringResult {
    start_pos := l.position
    c1 := l.current_char
    c2 := lexer_peek_char(l)
    c3 := lexer_peek_char2(l)
    
    // Three-character operators: ::=, ..=
    (c1 == 58 && c2 == 58 && c3 == 61) ?  // "::="
        | true => {
            l = lexer_read_char(l)
            l = lexer_read_char(l)
            l = lexer_read_char(l)
            return LexerStringResult { lexer: l, str: "::=" }
        }
        | false => {}
    
    (c1 == 46 && c2 == 46 && c3 == 61) ?  // "..="
        | true => {
            l = lexer_read_char(l)
            l = lexer_read_char(l)
            l = lexer_read_char(l)
            return LexerStringResult { lexer: l, str: "..=" }
        }
        | false => {}
    
    // Two-character operators
    op2 := ""
    (c1 == 61 && c2 == 61) ? | true => { op2 = "==" } | false => {}
    (c1 == 33 && c2 == 61) ? | true => { op2 = "!=" } | false => {}
    (c1 == 60 && c2 == 61) ? | true => { op2 = "<=" } | false => {}
    (c1 == 62 && c2 == 61) ? | true => { op2 = ">=" } | false => {}
    (c1 == 38 && c2 == 38) ? | true => { op2 = "&&" } | false => {}
    (c1 == 124 && c2 == 124) ? | true => { op2 = "||" } | false => {}
    (c1 == 45 && c2 == 62) ? | true => { op2 = "->" } | false => {}
    (c1 == 61 && c2 == 62) ? | true => { op2 = "=>" } | false => {}
    (c1 == 58 && c2 == 61) ? | true => { op2 = ":=" } | false => {}
    (c1 == 58 && c2 == 58) ? | true => { op2 = "::" } | false => {}
    (c1 == 46 && c2 == 46) ? | true => { op2 = ".." } | false => {}
    (c1 == 60 && c2 == 60) ? | true => { op2 = "<<" } | false => {}
    (c1 == 62 && c2 == 62) ? | true => { op2 = ">>" } | false => {}
    
    string_len(op2) > 0 ?
        | true => {
            l = lexer_read_char(l)
            l = lexer_read_char(l)
            return LexerStringResult { lexer: l, str: op2 }
        }
        | false => {}
    
    // Single-character operators
    l = lexer_read_char(l)
    op := string_substring(l.input, start_pos, l.position)
    return LexerStringResult { lexer: l, str: op }
}

// Convert string to keyword if applicable
string_to_keyword = (s: string) Option<KeywordType> {
    string_equals(s, "loop") ? | true => return Option::Some(KeywordType::Loop) | false => {}
    string_equals(s, "in") ? | true => return Option::Some(KeywordType::In) | false => {}
    string_equals(s, "comptime") ? | true => return Option::Some(KeywordType::Comptime) | false => {}
    string_equals(s, "async") ? | true => return Option::Some(KeywordType::Async) | false => {}
    string_equals(s, "await") ? | true => return Option::Some(KeywordType::Await) | false => {}
    string_equals(s, "behavior") ? | true => return Option::Some(KeywordType::Behavior) | false => {}
    string_equals(s, "impl") ? | true => return Option::Some(KeywordType::Impl) | false => {}
    string_equals(s, "extern") ? | true => return Option::Some(KeywordType::Extern) | false => {}
    string_equals(s, "break") ? | true => return Option::Some(KeywordType::Break) | false => {}
    string_equals(s, "continue") ? | true => return Option::Some(KeywordType::Continue) | false => {}
    string_equals(s, "return") ? | true => return Option::Some(KeywordType::Return) | false => {}
    string_equals(s, "type") ? | true => return Option::Some(KeywordType::Type) | false => {}
    string_equals(s, "void") ? | true => return Option::Some(KeywordType::Void) | false => {}
    string_equals(s, "true") ? | true => return Option::Some(KeywordType::True) | false => {}
    string_equals(s, "false") ? | true => return Option::Some(KeywordType::False) | false => {}
    
    return Option::None
}

// Result type for next token
LexerTokenResult = {
    lexer: Lexer,
    token: Token,
}

// Get next token - main lexer function
lexer_next_token = (l: Lexer) LexerTokenResult {
    l = lexer_skip_whitespace(l)
    
    start_pos := l.position
    start_line := l.line
    start_column := l.column
    
    // Default to EOF
    token_type := TokenType::Eof
    
    // Check for EOF
    l.current_char == -1 ?
        | true => {
            token_type = TokenType::Eof
        }
        | false => {
            // Comments
            l.current_char == 47 ?  // '/'
                | true => {
                    next := lexer_peek_char(l)
                    next == 47 ?  // "//"
                        | true => {
                            result := lexer_skip_line_comment(l)
                            l = result.lexer
                            comment := result.str
                            token_type = TokenType::Comment(comment)
                        }
                        | false => {
                            next == 42 ?  // "/*"
                                | true => {
                                    result := lexer_skip_block_comment(l)
                                    l = result.lexer
                                    comment := result.str
                                    token_type = TokenType::Comment(comment)
                                }
                                | false => {
                                    // Just a division operator
                                    result := lexer_read_operator(l)
                                    l = result.lexer
                                    op := result.str
                                    token_type = TokenType::Operator(op)
                                }
                        }
                }
                | false => {}
            
            // Identifier or keyword
            // Check for identifier or keyword (starts with letter, _, or @)
            is_id_start := (l.current_char >= 65 && l.current_char <= 90) || (l.current_char >= 97 && l.current_char <= 122) || l.current_char == 95 || l.current_char == 64
            token_type == TokenType::Eof && is_id_start ?
                | true => {
                    result := lexer_read_identifier(l)
                    l = result.lexer
                    ident := result.str
                    
                    keyword_opt := string_to_keyword(ident)
                    keyword_opt ?
                        | Some(kw) => { token_type = TokenType::Keyword(kw) }
                        | None => { token_type = TokenType::Identifier(ident) }
                }
                | false => {}
            
            // Number
            // Check for number
            token_type == TokenType::Eof && (l.current_char >= 48 && l.current_char <= 57) ?
                | true => {
                    result := lexer_read_number(l)
                    l = result.lexer
                    num := result.str
                    is_float := result.is_float
                    
                    is_float ?
                        | true => { token_type = TokenType::Float(num) }
                        | false => { token_type = TokenType::Integer(num) }
                }
                | false => {}
            
            // String literal
            token_type == TokenType::Eof && l.current_char == 34 ?  // '"'
                | true => {
                    result := lexer_read_string(l)
                    l = result.lexer
                    str := result.str
                    token_type = TokenType::StringLiteral(str)
                }
                | false => {}
            
            // Symbols
            // Check for symbol
            is_sym := l.current_char == 40 || l.current_char == 41 || // ( )
                     l.current_char == 123 || l.current_char == 125 || // { }
                     l.current_char == 91 || l.current_char == 93 || // [ ]
                     l.current_char == 59 || l.current_char == 44 || // ; ,
                     l.current_char == 124 || l.current_char == 38 || // | &
                     l.current_char == 46 || l.current_char == 63 // . ?
            token_type == TokenType::Eof && is_sym ?
                | true => {
                    c := l.current_char
                    l = lexer_read_char(l)
                    token_type = TokenType::Symbol(c)
                }
                | false => {}
            
            // Operators
            // Check for operator
            is_op := l.current_char == 43 || l.current_char == 45 || l.current_char == 42 || l.current_char == 47 || // + - * /
                    l.current_char == 61 || l.current_char == 33 || l.current_char == 60 || l.current_char == 62 || // = ! < >
                    l.current_char == 38 || l.current_char == 124 || l.current_char == 58 // & | :
            token_type == TokenType::Eof && is_op ?
                | true => {
                    result := lexer_read_operator(l)
                    l = result.lexer
                    op := result.str
                    token_type = TokenType::Operator(op)
                }
                | false => {}
            
            // Unknown character - treat as symbol
            token_type == TokenType::Eof ?
                | true => {
                    c := l.current_char
                    l = lexer_read_char(l)
                    token_type = TokenType::Symbol(c)
                }
                | false => {}
        }
    
    token := Token {
        token_type: token_type,
        line: start_line,
        column: start_column,
        start: start_pos,
        end: l.position,
    }
    
    return LexerTokenResult { lexer: l, token: token }
}

// Tokenize entire input
lexer_tokenize_all = (input: string) Vec<Token> {
    tokens := vec_new<Token>()
    lexer := lexer_new(input)
    
    loop {
        result := lexer_next_token(lexer)
        lexer = result.lexer
        token := result.token
        
        vec_push(&tokens, token)
        
        token.token_type ?
            | Eof => break
            | _ => {}
    }
    
    return tokens
}

// Helper to check if we reached EOF
lexer_is_eof = (l: Lexer) bool {
    return l.current_char == -1
}

// Export the lexer interface
export {
    Lexer,
    Token,
    TokenType,
    KeywordType,
    lexer_new,
    lexer_next_token,
    lexer_tokenize_all,
    lexer_is_eof,
}