// Task Executor - Concurrent task execution system for Zen
// Provides task execution with thread pool management (colorless - allocator controlled)

core := @std
build := @std
thread := build.import("thread")
{ Vec, DynVec } = @std
result := build.import("result")
sync := build.import("sync")
io := build.import("io")

// Task status enum
TaskStatus:
    Pending,
    Running,
    Completed,
    Failed,
    Cancelled

// Task priority levels
Priority : 
    Low = 0,
    Normal = 1,
    High = 2,
    Critical = 3

// Generic task result
TaskResult<T>:
    Success: T,
    Failure: string,
    Cancelled

// Task structure
Task<T>: {
    id: u64,
    name: string,
    priority: Priority,
    status: TaskStatus,
    func: () TaskResult<T>,
    result: Option<TaskResult<T>>,
    created_at: u64,
    started_at: Option<u64>,
    completed_at: Option<u64>
}

// Task executor configuration
ExecutorConfig: {
    num_threads: usize,
    queue_size: usize,
    enable_metrics: bool,
    panic_handler: Option<fn(string)(void>
}

// Default configuration
default_config = () ExecutorConfig   {
    return ExecutorConfig{
        num_threads: thread.hardware_concurrency(),
        queue_size: 1024,
        enable_metrics: false,
        panic_handler: null
    }
}

// Task executor
TaskExecutor := {
    config: ExecutorConfig,
    thread_pool: DynVec<thread.Thread>,
    task_queue: sync.Queue<Task<any>>,
    active_tasks: sync.Map<u64, Task<any>>,
    completed_tasks: DynVec<Task<any>>,
    next_task_id: sync.Atomic<u64>,
    shutdown: sync.Atomic<bool>,
    metrics: Option<ExecutorMetrics>
}

// Executor metrics
ExecutorMetrics: {
    tasks_submitted: sync.Atomic<u64>,
    tasks_completed: sync.Atomic<u64>,
    tasks_failed: sync.Atomic<u64>,
    tasks_cancelled: sync.Atomic<u64>,
    total_execution_time: sync.Atomic<u64>,
    average_wait_time: sync.Atomic<u64>
}

// Create a new task executor
new = (config: ExecutorConfig) TaskExecutor {
    executor := core.alloc<TaskExecutor>()
    executor.config = config
    executor.task_queue = sync.Queue.new(config.queue_size)
    executor.active_tasks = sync.Map.new()
    executor.completed_tasks = DynVec.new()
    executor.next_task_id = sync.Atomic.new(1)
    executor.shutdown = sync.Atomic.new(false)
    
    config.enable_metrics ? {
        executor.metrics = create_metrics()
    }
    
    // Start worker threads
    executor.thread_pool = DynVec.new()
    i := 0
    loop {
        i < config.num_threads ? | false { break } | true {
            worker := thread.spawn(worker_loop, executor)
            executor.thread_pool.push(worker)
            i += 1
        }
    }
    
    return executor
}

// Create metrics instance
create_metrics = () ExecutorMetrics {
    metrics := core.alloc<ExecutorMetrics>()
    metrics.tasks_submitted = sync.Atomic.new(0)
    metrics.tasks_completed = sync.Atomic.new(0)
    metrics.tasks_failed = sync.Atomic.new(0)
    metrics.tasks_cancelled = sync.Atomic.new(0)
    metrics.total_execution_time = sync.Atomic.new(0)
    metrics.average_wait_time = sync.Atomic.new(0)
    return metrics
}

// Submit a task for execution
submit<T> = (executor: TaskExecutor, name: string, priority: Priority, func: () TaskResult<T>) u64 {
    task_id := executor.next_task_id.fetch_add(1)
    
    task := Task<T>{
        id: task_id,
        name: name,
        priority: priority,
        status: TaskStatus.Pending,
        func: func,
        result: Option.None,
        created_at: thread.current_time_millis(),
        started_at: Option.None,
        completed_at: null
    }
    
    // Update metrics
        executor.metrics != Option.None ? {
        executor.metrics.tasks_submitted.fetch_add(1)
    }
    
    // Add to queue based on priority
    priority == Priority.Critical ? {
        executor.task_queue.push_front(task)
    } | false {
        executor.task_queue.push(task)
    }
    
    return task_id
}

// Worker thread loop
worker_loop = (executor: TaskExecutor) void   {
    loop {
        !executor.shutdown.load() ? | false { break } | true {
        // Try to get a task from the queue
        task_opt := executor.task_queue.pop_timeout(100)
        
        task_opt.is_some() ? {
            task_opt ? | Some(task) {
            
            // Mark task as running
            task.status = TaskStatus.Running
            task.started_at = thread.current_time_millis()
            executor.active_tasks.insert(task.id, task)
            
            // Execute the task
            result := task.func()
            result ?
                | Ok(value) {
                    task.result = Option.Some(value)
                    task.status = TaskStatus.Completed
                    
                    executor.metrics ?
                        | Option.None
                        | metrics { metrics.tasks_completed.fetch_add(1) }
                }
                | Err(error) {
                    task.result = TaskResult.Failure(error.to_string())
                    task.status = TaskStatus.Failed
                    
                    executor.metrics ?
                        | Option.None
                        | metrics { metrics.tasks_failed.fetch_add(1) }
                    
                    // Call panic handler if configured
                    executor.config.panic_handler ?
                        | Option.None
                        | handler { handler(error.to_string()) }
                }
            
            // Mark task as completed
            task.completed_at = thread.current_time_millis()
            
            // Update metrics
        executor.metrics != Option.None ? | {
                execution_time := task.completed_at - task.started_at
                executor.metrics.total_execution_time.fetch_add(execution_time)
                
                wait_time := task.started_at - task.created_at
                current_avg := executor.metrics.average_wait_time.load()
                completed := executor.metrics.tasks_completed.load()
                new_avg := ((current_avg * (completed - 1)) + wait_time) / completed
                executor.metrics.average_wait_time.store(new_avg)
            }
            
            // Move to completed tasks
            executor.active_tasks.remove(task.id)
            executor.completed_tasks.push(task)
        }
        }
    }
}

// Wait for a specific task to complete
wait_for = (executor: Ptr<TaskExecutor>, task_id: u64) Option<TaskResult<any>>   {
    // Check if already completed
    executor.completed_tasks.loop((task) {
        task.id == task_id ? {
            return task.result
        }
    })
    
    // Wait for task to complete
    loop {
        executor.active_tasks.contains(task_id) ? {
            thread.sleep(10)
        } | false {
            // Check completed tasks again
            executor.completed_tasks.loop((task) {
                task.id == task_id ? {
                    return task.result
                }
            }
            return null
        }
    }
}

// Cancel a task
cancel = (executor: Ptr<TaskExecutor>, task_id: u64) bool   {
    // Check if task is still pending
    queue_tasks := executor.task_queue.to_vec()
    queue_tasks.loop((i, task) {
        task.id == task_id ? {
            task.status = TaskStatus.Cancelled
            task.result = TaskResult.Cancelled
            executor.task_queue.remove(i)
            
            executor.metrics != null ? {
                executor.metrics.tasks_cancelled.fetch_add(1)
            }
            
            return true
        }
    }
    
    // Cannot cancel running or completed tasks
    return false
}

// Get task status
get_status = (executor: Ptr<TaskExecutor>, task_id: u64) Option<TaskStatus>   {
    // Check active tasks
    executor.active_tasks.contains(task_id) ? {
        task := executor.active_tasks.get(task_id)
        return task.status
    }
    
    // Check completed tasks
    executor.completed_tasks.loop((task) {
        task.id == task_id ? {
            return task.status
        }
    }
    
    // Check queue
    queue_tasks := executor.task_queue.to_vec()
    queue_tasks.loop((task) {
        task.id == task_id ? {
            return task.status
        }
    }
    
    return null
}

// Shutdown the executor
shutdown = (executor: Ptr<TaskExecutor>, wait_for_completion: bool) void   {
    wait_for_completion ? {
        // Wait for all tasks to complete
        loop {
            executor.task_queue.size() > 0 || executor.active_tasks.size() > 0 ? | false { break } | true {
                thread.sleep(100)
            }
        }
    }
    
    // Signal shutdown
    executor.shutdown.store(true)
    
    // Join all worker threads
    executor.thread_pool.loop((worker) {
        worker.join()
    }
}

// Get executor metrics
get_metrics = (executor: Ptr<TaskExecutor>) Option<ExecutorMetrics>   {
    return executor.metrics
}

// Batch submit multiple tasks
batch_submit<T> = (executor: Ptr<TaskExecutor>, tasks: Vec<struct{name: string, priority: Priority, func: fn()(TaskResult<T>)}) DynVec<u64> {
    task_ids := DynVec.new()
    
    tasks.loop((task_info) {
        id := submit(executor, task_info.name, task_info.priority, task_info.func)
        task_ids.push(id)
    }
    
    return task_ids
}

// Wait for all tasks in a batch
wait_for_batch = (executor: Ptr<TaskExecutor>, task_ids: Vec<u64>) DynVec<TaskResult<any>>   {
    results := DynVec.new()
    
    task_ids.loop((id) {
        result := wait_for(executor, id)
        result != null ? {
            results.push(result)
        }
    }
    
    return results
}

// Create a task group for related tasks
TaskGroup := {
    executor: Ptr<TaskExecutor>,
    task_ids: DynVec<u64>,
    name: string
}

// Create a new task group
new_group = (executor: Ptr<TaskExecutor>, name: string) Ptr<TaskGroup> {
    group := core.alloc<TaskGroup>()
    group.executor = executor
    group.task_ids = DynVec.new()
    group.name = name
    return group
}

// Add a task to the group
add_to_group<T> = (group: Ptr<TaskGroup>, name: string, priority: Priority, func: fn()(TaskResult<T>) u64 {
    task_id := submit(group.executor, group.name + "." + name, priority, func)
    group.task_ids.push(task_id)
    return task_id
}

// Wait for all tasks in the group
wait_group = (group: Ptr<TaskGroup>) DynVec<TaskResult<any>>   {
    return wait_for_batch(group.executor, group.task_ids)
}

// Cancel all tasks in the group
cancel_group = (group: Ptr<TaskGroup>) i32   {
    cancelled := 0
    group.task_ids.loop((id) {
        cancel(group.executor, id) ? {
            cancelled += 1
        }
    }
    return cancelled
}