// Enhanced Zen Parser - Complete self-hosted parser implementation
// This parser handles the full Zen language including imports

core := @std.core
vec := @std.vec
hashmap := @std.hashmap
io := @std.io
lexer := @std.lexer
token := @std.token
ast := @std.ast

// Parser state with better error handling
Parser = {
    tokens:: Vec<Token>,
    current:: u32,
    errors:: Vec<ParseError>,
    panic_mode:: bool,
    had_error:: bool,
}

// Parse error information
ParseError = {
    message: string,
    token: Token,
    line: u32,
    column: u32,
}

// Create a new parser
parser_new = (tokens: Vec<Token>) Parser {
    Parser{
        tokens: tokens,
        current: 0,
        errors: vec_new<ParseError>(),
        panic_mode: false,
        had_error: false,
    }
}

// Error recovery
parser_synchronize = (p:: Ptr<Parser>) void {
    p.panic_mode = false
    
    loop !p.is_at_end() {
        p.previous().type == TokenType.Semicolon ? 
            | true => return
            | false => {}
        
        p.peek().type ?
            | TokenType.Function => return
            | TokenType.Struct => return
            | TokenType.Enum => return
            | TokenType.Import => return
            | TokenType.Extern => return
            | TokenType.If => return
            | TokenType.Loop => return
            | TokenType.Return => return
            | _ => {}
        
        p.advance()
    }
}

// Error reporting
parser_error = (p:: Ptr<Parser>, message: string) void {
    p.panic_mode ? | true => return | false => {}
    
    p.panic_mode = true
    p.had_error = true
    
    token := p.peek()
    error := ParseError{
        message: message,
        token: token,
        line: token.line,
        column: token.column,
    }
    
    p.errors.push(error)
    
    // Print error immediately for debugging
    io.println("[Parser Error] Line $(token.line):$(token.column): $(message)")
    io.println("  at token: $(token.lexeme)")
}

// Token navigation
parser_peek = (p:: Ptr<Parser>) Token {
    p.current < p.tokens.len() ?
        | true => return p.tokens.at(p.current)
        | false => return Token{ type: TokenType.Eof }
}

parser_previous = (p:: Ptr<Parser>) Token {
    p.current > 0 ?
        | true => return p.tokens.at(p.current - 1)
        | false => return Token{ type: TokenType.Eof }
}

parser_advance = (p:: Ptr<Parser>) Token {
    !p.is_at_end() ?
        | true => p.current = p.current + 1
        | false => {}
    return p.previous()
}

parser_is_at_end = (p:: Ptr<Parser>) bool {
    return p.peek().type == TokenType.Eof
}

parser_check = (p:: Ptr<Parser>, type: TokenType) bool {
    p.is_at_end() ? | true => return false | false => {}
    return p.peek().type == type
}

parser_match = (p:: Ptr<Parser>, types: Vec<TokenType>) bool {
    range(0, types.len()).loop(i -> {
        p.check(types.at(i)) ? | true => {
            p.advance()
            return true
        } | false => {}
    })
    return false
}

parser_consume = (p:: Ptr<Parser>, type: TokenType, message: string) Token {
    p.check(type) ? 
        | true => return p.advance()
        | false => {
            p.error(message)
            return p.peek()
        }
}

// Parse a complete program
parse_program = (p:: Ptr<Parser>) ast.Program {
    declarations := vec_new<ast.Declaration>()
    
    loop !p.is_at_end() {
        decl := p.parse_declaration()
        decl.is_valid() ? 
            | true => declarations.push(decl)
            | false => p.synchronize()
    }
    
    return ast.Program{
        declarations: declarations,
        had_errors: p.had_error,
    }
}

// Parse top-level declarations
parse_declaration = (p:: Ptr<Parser>) ast.Declaration {
    // Handle imports (no comptime wrapper needed)
    p.check(TokenType.Identifier) && p.peek().lexeme == "@std" ?
        | true => return p.parse_std_import()
        | false => {}
    
    p.peek().type ?
        | TokenType.Function => return p.parse_function()
        | TokenType.Struct => return p.parse_struct()
        | TokenType.Enum => return p.parse_enum()
        | TokenType.Extern => return p.parse_extern()
        | TokenType.Comptime => return p.parse_comptime()
        | TokenType.Const => return p.parse_const()
        | _ => {
            // Could be a variable declaration or import
            p.peek().type == TokenType.Identifier ?
                | true => {
                    // Check for import pattern: name := @std.module or name := module.import()
                    lookahead := p.peek_next()
                    lookahead.type == TokenType.ColonEqual ?
                        | true => return p.parse_import_or_variable()
                        | false => {}
                }
                | false => {}
            
            p.error("Expected declaration")
            p.advance()
            return ast.Declaration.Invalid
        }
}

// Parse imports (both @std style and build.import style)
parse_import_or_variable = (p:: Ptr<Parser>) ast.Declaration {
    name := p.consume(TokenType.Identifier, "Expected identifier")
    p.consume(TokenType.ColonEqual, "Expected ':='")
    
    // Check for @std import
    p.check(TokenType.At) ? | true => {
        p.advance()
        p.consume(TokenType.Identifier, "Expected 'std' after '@'")
        p.consume(TokenType.Dot, "Expected '.'")
        module := p.consume(TokenType.Identifier, "Expected module name")
        
        return ast.Declaration.Import(ast.Import{
            name: name.lexeme,
            module: module.lexeme,
            is_std: true,
        })
    } | false => {}
    
    // Check for build.import() style
    p.check(TokenType.Identifier) ? | true => {
        obj := p.advance()
        p.check(TokenType.Dot) ? | true => {
            p.advance()
            p.consume(TokenType.Identifier, "Expected 'import'")
            p.consume(TokenType.LeftParen, "Expected '('")
            module_str := p.consume(TokenType.String, "Expected module name string")
            p.consume(TokenType.RightParen, "Expected ')'")
            
            return ast.Declaration.Import(ast.Import{
                name: name.lexeme,
                module: module_str.lexeme,
                is_std: false,
                builder: obj.lexeme,
            })
        } | false => {
            // Regular variable declaration
            expr := p.parse_expression()
            return ast.Declaration.Variable(ast.Variable{
                name: name.lexeme,
                initializer: expr,
                is_mutable: false,
            })
        }
    } | false => {}
    
    // Fall back to expression
    expr := p.parse_expression()
    return ast.Declaration.Variable(ast.Variable{
        name: name.lexeme,
        initializer: expr,
        is_mutable: false,
    })
}

// Parse function declaration
parse_function = (p:: Ptr<Parser>) ast.Declaration {
    p.consume(TokenType.Function, "Expected 'function'")
    name := p.consume(TokenType.Identifier, "Expected function name")
    
    // Parse generic parameters if present
    generics := vec_new<ast.GenericParam>()
    p.check(TokenType.Less) ? | true => {
        p.advance()
        loop {
            param_name := p.consume(TokenType.Identifier, "Expected generic parameter name")
            generics.push(ast.GenericParam{ name: param_name.lexeme })
            
            !p.match([TokenType.Comma]) ? | true => break | false => {}
        }
        p.consume(TokenType.Greater, "Expected '>'")
    } | false => {}
    
    p.consume(TokenType.LeftParen, "Expected '('")
    
    // Parse parameters
    params := vec_new<ast.Parameter>()
    !p.check(TokenType.RightParen) ? | true => {
        loop {
            param_name := p.consume(TokenType.Identifier, "Expected parameter name")
            
            // Check for type annotation
            type_ann := p.check(TokenType.Colon) ? | true => {
                p.advance()
                p.parse_type()
            } | false => ast.Type.Inferred
            
            params.push(ast.Parameter{
                name: param_name.lexeme,
                type: type_ann,
            })
            
            !p.match([TokenType.Comma]) ? | true => break | false => {}
        }
    } | false => {}
    
    p.consume(TokenType.RightParen, "Expected ')'")
    
    // Parse return type
    return_type := p.parse_type()
    
    // Parse body
    body := p.parse_block_statement()
    
    return ast.Declaration.Function(ast.Function{
        name: name.lexeme,
        generics: generics,
        params: params,
        return_type: return_type,
        body: body,
    })
}

// Parse struct declaration
parse_struct = (p:: Ptr<Parser>) ast.Declaration {
    p.consume(TokenType.Struct, "Expected 'struct'")
    name := p.consume(TokenType.Identifier, "Expected struct name")
    
    p.consume(TokenType.LeftBrace, "Expected '{'")
    
    fields := vec_new<ast.Field>()
    loop !p.check(TokenType.RightBrace) {
        field_name := p.consume(TokenType.Identifier, "Expected field name")
        
        // Check for mutability marker ::
        is_mutable := p.match([TokenType.ColonColon])
        
        p.consume(TokenType.Colon, "Expected ':'")
        field_type := p.parse_type()
        
        fields.push(ast.Field{
            name: field_name.lexeme,
            type: field_type,
            is_mutable: is_mutable,
        })
        
        p.match([TokenType.Comma])
        
        // Allow trailing comma
        p.check(TokenType.RightBrace) ? | true => break | false => {}
    }
    
    p.consume(TokenType.RightBrace, "Expected '}'")
    
    return ast.Declaration.Struct(ast.Struct{
        name: name.lexeme,
        fields: fields,
    })
}

// Parse enum declaration
parse_enum = (p:: Ptr<Parser>) ast.Declaration {
    p.consume(TokenType.Enum, "Expected 'enum'")
    name := p.consume(TokenType.Identifier, "Expected enum name")
    
    p.consume(TokenType.LeftBrace, "Expected '{'")
    
    variants := vec_new<ast.EnumVariant>()
    loop !p.check(TokenType.RightBrace) {
        p.consume(TokenType.Pipe, "Expected '|'")
        variant_name := p.consume(TokenType.Identifier, "Expected variant name")
        
        // Check for associated data
        fields := vec_new<ast.Field>()
        p.check(TokenType.LeftParen) ? | true => {
            p.advance()
            loop !p.check(TokenType.RightParen) {
                field_name := p.consume(TokenType.Identifier, "Expected field name")
                p.consume(TokenType.Colon, "Expected ':'")
                field_type := p.parse_type()
                
                fields.push(ast.Field{
                    name: field_name.lexeme,
                    type: field_type,
                    is_mutable: false,
                })
                
                !p.match([TokenType.Comma]) ? | true => break | false => {}
            }
            p.consume(TokenType.RightParen, "Expected ')'")
        } | false => {}
        
        variants.push(ast.EnumVariant{
            name: variant_name.lexeme,
            fields: fields,
        })
    }
    
    p.consume(TokenType.RightBrace, "Expected '}'")
    
    return ast.Declaration.Enum(ast.Enum{
        name: name.lexeme,
        variants: variants,
    })
}

// Parse extern declaration
parse_extern = (p:: Ptr<Parser>) ast.Declaration {
    p.consume(TokenType.Extern, "Expected 'extern'")
    name := p.consume(TokenType.Identifier, "Expected function name")
    p.consume(TokenType.Equal, "Expected '='")
    p.consume(TokenType.LeftParen, "Expected '('")
    
    params := vec_new<ast.Type>()
    !p.check(TokenType.RightParen) ? | true => {
        loop {
            param_name := p.consume(TokenType.Identifier, "Expected parameter name")
            p.consume(TokenType.Colon, "Expected ':'")
            param_type := p.parse_type()
            params.push(param_type)
            
            !p.match([TokenType.Comma]) ? | true => break | false => {}
        }
    } | false => {}
    
    p.consume(TokenType.RightParen, "Expected ')'")
    
    return_type := p.parse_type()
    
    return ast.Declaration.Extern(ast.ExternFunction{
        name: name.lexeme,
        params: params,
        return_type: return_type,
    })
}

// Parse comptime block
parse_comptime = (p:: Ptr<Parser>) ast.Declaration {
    p.consume(TokenType.Comptime, "Expected 'comptime'")
    p.consume(TokenType.LeftBrace, "Expected '{'")
    
    statements := vec_new<ast.Statement>()
    loop !p.check(TokenType.RightBrace) {
        stmt := p.parse_statement()
        statements.push(stmt)
    }
    
    p.consume(TokenType.RightBrace, "Expected '}'")
    
    return ast.Declaration.Comptime(ast.ComptimeBlock{
        statements: statements,
    })
}

// Parse const declaration
parse_const = (p:: Ptr<Parser>) ast.Declaration {
    p.consume(TokenType.Const, "Expected 'const'")
    name := p.consume(TokenType.Identifier, "Expected constant name")
    
    // Optional type annotation
    type_ann := p.check(TokenType.Colon) ? | true => {
        p.advance()
        p.parse_type()
    } | false => ast.Type.Inferred
    
    p.consume(TokenType.Equal, "Expected '='")
    value := p.parse_expression()
    
    return ast.Declaration.Const(ast.Const{
        name: name.lexeme,
        type: type_ann,
        value: value,
    })
}

// Parse type annotations
parse_type = (p:: Ptr<Parser>) ast.Type {
    // Check for pointer type
    p.check(TokenType.Star) ? | true => {
        p.advance()
        inner := p.parse_type()
        return ast.Type.Pointer(Box.new(inner))
    } | false => {}
    
    // Check for array type
    p.check(TokenType.LeftBracket) ? | true => {
        p.advance()
        size := p.check(TokenType.Integer) ? | true => {
            size_token := p.advance()
            size_token.int_value
        } | false => 0  // Dynamic array
        p.consume(TokenType.RightBracket, "Expected ']'")
        element := p.parse_type()
        return ast.Type.Array(Box.new(element), size)
    } | false => {}
    
    // Check for function type
    p.check(TokenType.LeftParen) ? | true => {
        // Could be function type or grouped type
        // For now, parse as grouped type
        p.advance()
        type := p.parse_type()
        p.consume(TokenType.RightParen, "Expected ')'")
        return type
    } | false => {}
    
    // Parse basic or custom type
    type_name := p.consume(TokenType.Identifier, "Expected type name")
    
    // Check for generic parameters
    p.check(TokenType.Less) ? | true => {
        p.advance()
        args := vec_new<ast.Type>()
        loop {
            arg := p.parse_type()
            args.push(arg)
            !p.match([TokenType.Comma]) ? | true => break | false => {}
        }
        p.consume(TokenType.Greater, "Expected '>'")
        
        return ast.Type.Generic(type_name.lexeme, args)
    } | false => {}
    
    // Map to built-in type or custom
    type_name.lexeme ?
        | "i8" => ast.Type.I8
        | "i16" => ast.Type.I16
        | "i32" => ast.Type.I32
        | "i64" => ast.Type.I64
        | "u8" => ast.Type.U8
        | "u16" => ast.Type.U16
        | "u32" => ast.Type.U32
        | "u64" => ast.Type.U64
        | "f32" => ast.Type.F32
        | "f64" => ast.Type.F64
        | "bool" => ast.Type.Bool
        | "string" => ast.Type.String
        | "void" => ast.Type.Void
        | _ => ast.Type.Custom(type_name.lexeme)
}

// Parse statements
parse_statement = (p:: Ptr<Parser>) ast.Statement {
    p.peek().type ?
        | TokenType.If => p.parse_if_statement()
        | TokenType.Loop => p.parse_loop_statement()
        | TokenType.Return => p.parse_return_statement()
        | TokenType.LeftBrace => p.parse_block_statement()
        | _ => p.parse_expression_statement()
}

// Parse if statement
parse_if_statement = (p:: Ptr<Parser>) ast.Statement {
    p.consume(TokenType.If, "Expected 'if'")
    condition := p.parse_expression()
    
    p.consume(TokenType.Question, "Expected '?'")
    p.consume(TokenType.Pipe, "Expected '|'")
    p.consume(TokenType.True, "Expected 'true'")
    p.consume(TokenType.Arrow, "Expected '=>'")
    then_branch := p.parse_statement()
    
    p.consume(TokenType.Pipe, "Expected '|'")
    p.consume(TokenType.False, "Expected 'false'")
    p.consume(TokenType.Arrow, "Expected '=>'")
    else_branch := p.parse_statement()
    
    return ast.Statement.If(ast.IfStatement{
        condition: condition,
        then_branch: Box.new(then_branch),
        else_branch: Box.new(else_branch),
    })
}

// Parse loop statement
parse_loop_statement = (p:: Ptr<Parser>) ast.Statement {
    p.consume(TokenType.Loop, "Expected 'loop'")
    
    // Check for condition
    condition := !p.check(TokenType.LeftBrace) ? | true => {
        p.parse_expression()
    } | false => ast.Expression.Bool(true)
    
    body := p.parse_block_statement()
    
    return ast.Statement.Loop(ast.LoopStatement{
        condition: condition,
        body: Box.new(body),
    })
}

// Parse return statement
parse_return_statement = (p:: Ptr<Parser>) ast.Statement {
    p.consume(TokenType.Return, "Expected 'return'")
    
    value := !p.check(TokenType.Semicolon) && !p.check(TokenType.RightBrace) ? 
        | true => p.parse_expression()
        | false => ast.Expression.Void
    
    p.match([TokenType.Semicolon])
    
    return ast.Statement.Return(ast.ReturnStatement{
        value: value,
    })
}

// Parse block statement
parse_block_statement = (p:: Ptr<Parser>) ast.Statement {
    p.consume(TokenType.LeftBrace, "Expected '{'")
    
    statements := vec_new<ast.Statement>()
    loop !p.check(TokenType.RightBrace) && !p.is_at_end() {
        stmt := p.parse_statement()
        statements.push(stmt)
    }
    
    p.consume(TokenType.RightBrace, "Expected '}'")
    
    return ast.Statement.Block(ast.BlockStatement{
        statements: statements,
    })
}

// Parse expression statement
parse_expression_statement = (p:: Ptr<Parser>) ast.Statement {
    expr := p.parse_expression()
    p.match([TokenType.Semicolon])
    return ast.Statement.Expression(expr)
}

// Parse expressions (simplified for now)
parse_expression = (p:: Ptr<Parser>) ast.Expression {
    p.parse_assignment()
}

parse_assignment = (p:: Ptr<Parser>) ast.Expression {
    expr := p.parse_logical_or()
    
    p.check(TokenType.Equal) ? | true => {
        p.advance()
        value := p.parse_assignment()
        
        expr.kind ?
            | ast.ExpressionKind.Identifier -> name => {
                return ast.Expression.Assignment(ast.Assignment{
                    target: name,
                    value: Box.new(value),
                })
            }
            | _ => {
                p.error("Invalid assignment target")
                return expr
            }
    } | false => {}
    
    return expr
}

parse_logical_or = (p:: Ptr<Parser>) ast.Expression {
    expr := p.parse_logical_and()
    
    loop p.match([TokenType.PipePipe]) {
        op := p.previous()
        right := p.parse_logical_and()
        expr = ast.Expression.Binary(ast.BinaryOp{
            left: Box.new(expr),
            operator: ast.BinaryOperator.LogicalOr,
            right: Box.new(right),
        })
    }
    
    return expr
}

parse_logical_and = (p:: Ptr<Parser>) ast.Expression {
    expr := p.parse_equality()
    
    loop p.match([TokenType.AmpAmp]) {
        op := p.previous()
        right := p.parse_equality()
        expr = ast.Expression.Binary(ast.BinaryOp{
            left: Box.new(expr),
            operator: ast.BinaryOperator.LogicalAnd,
            right: Box.new(right),
        })
    }
    
    return expr
}

parse_equality = (p:: Ptr<Parser>) ast.Expression {
    expr := p.parse_comparison()
    
    loop p.match([TokenType.EqualEqual, TokenType.BangEqual]) {
        op := p.previous()
        right := p.parse_comparison()
        
        operator := op.type == TokenType.EqualEqual ?
            | true => ast.BinaryOperator.Equal
            | false => ast.BinaryOperator.NotEqual
        
        expr = ast.Expression.Binary(ast.BinaryOp{
            left: Box.new(expr),
            operator: operator,
            right: Box.new(right),
        })
    }
    
    return expr
}

parse_comparison = (p:: Ptr<Parser>) ast.Expression {
    expr := p.parse_addition()
    
    loop p.match([TokenType.Less, TokenType.Greater, TokenType.LessEqual, TokenType.GreaterEqual]) {
        op := p.previous()
        right := p.parse_addition()
        
        operator := op.type ?
            | TokenType.Less => ast.BinaryOperator.Less
            | TokenType.Greater => ast.BinaryOperator.Greater
            | TokenType.LessEqual => ast.BinaryOperator.LessEqual
            | TokenType.GreaterEqual => ast.BinaryOperator.GreaterEqual
            | _ => ast.BinaryOperator.Equal  // Should not happen
        
        expr = ast.Expression.Binary(ast.BinaryOp{
            left: Box.new(expr),
            operator: operator,
            right: Box.new(right),
        })
    }
    
    return expr
}

parse_addition = (p:: Ptr<Parser>) ast.Expression {
    expr := p.parse_multiplication()
    
    loop p.match([TokenType.Plus, TokenType.Minus]) {
        op := p.previous()
        right := p.parse_multiplication()
        
        operator := op.type == TokenType.Plus ?
            | true => ast.BinaryOperator.Add
            | false => ast.BinaryOperator.Subtract
        
        expr = ast.Expression.Binary(ast.BinaryOp{
            left: Box.new(expr),
            operator: operator,
            right: Box.new(right),
        })
    }
    
    return expr
}

parse_multiplication = (p:: Ptr<Parser>) ast.Expression {
    expr := p.parse_unary()
    
    loop p.match([TokenType.Star, TokenType.Slash, TokenType.Percent]) {
        op := p.previous()
        right := p.parse_unary()
        
        operator := op.type ?
            | TokenType.Star => ast.BinaryOperator.Multiply
            | TokenType.Slash => ast.BinaryOperator.Divide
            | TokenType.Percent => ast.BinaryOperator.Modulo
            | _ => ast.BinaryOperator.Multiply  // Should not happen
        
        expr = ast.Expression.Binary(ast.BinaryOp{
            left: Box.new(expr),
            operator: operator,
            right: Box.new(right),
        })
    }
    
    return expr
}

parse_unary = (p:: Ptr<Parser>) ast.Expression {
    p.match([TokenType.Bang, TokenType.Minus, TokenType.Amp, TokenType.Star]) ? | true => {
        op := p.previous()
        expr := p.parse_unary()
        
        operator := op.type ?
            | TokenType.Bang => ast.UnaryOperator.LogicalNot
            | TokenType.Minus => ast.UnaryOperator.Negate
            | TokenType.Amp => ast.UnaryOperator.AddressOf
            | TokenType.Star => ast.UnaryOperator.Dereference
            | _ => ast.UnaryOperator.Negate  // Should not happen
        
        return ast.Expression.Unary(ast.UnaryOp{
            operator: operator,
            operand: Box.new(expr),
        })
    } | false => {}
    
    return p.parse_postfix()
}

parse_postfix = (p:: Ptr<Parser>) ast.Expression {
    expr := p.parse_primary()
    
    loop {
        p.match([TokenType.LeftParen]) ? | true => {
            // Function call
            args := vec_new<ast.Expression>()
            !p.check(TokenType.RightParen) ? | true => {
                loop {
                    arg := p.parse_expression()
                    args.push(arg)
                    !p.match([TokenType.Comma]) ? | true => break | false => {}
                }
            } | false => {}
            p.consume(TokenType.RightParen, "Expected ')'")
            
            expr = ast.Expression.Call(ast.CallExpression{
                callee: Box.new(expr),
                args: args,
            })
        } | false => {}
        
        p.match([TokenType.Dot]) ? | true => {
            // Field access
            field := p.consume(TokenType.Identifier, "Expected field name")
            expr = ast.Expression.FieldAccess(ast.FieldAccess{
                object: Box.new(expr),
                field: field.lexeme,
            })
        } | false => {}
        
        p.match([TokenType.LeftBracket]) ? | true => {
            // Array index
            index := p.parse_expression()
            p.consume(TokenType.RightBracket, "Expected ']'")
            
            expr = ast.Expression.Index(ast.IndexExpression{
                array: Box.new(expr),
                index: Box.new(index),
            })
        } | false => {
            break
        }
    }
    
    return expr
}

parse_primary = (p:: Ptr<Parser>) ast.Expression {
    // Literals
    p.check(TokenType.True) ? | true => {
        p.advance()
        return ast.Expression.Bool(true)
    } | false => {}
    
    p.check(TokenType.False) ? | true => {
        p.advance()
        return ast.Expression.Bool(false)
    } | false => {}
    
    p.check(TokenType.Null) ? | true => {
        p.advance()
        return ast.Expression.Null
    } | false => {}
    
    p.check(TokenType.Integer) ? | true => {
        token := p.advance()
        return ast.Expression.Integer(token.int_value)
    } | false => {}
    
    p.check(TokenType.Float) ? | true => {
        token := p.advance()
        return ast.Expression.Float(token.float_value)
    } | false => {}
    
    p.check(TokenType.String) ? | true => {
        token := p.advance()
        return ast.Expression.String(token.string_value)
    } | false => {}
    
    p.check(TokenType.Identifier) ? | true => {
        token := p.advance()
        return ast.Expression.Identifier(token.lexeme)
    } | false => {}
    
    // Grouped expression
    p.check(TokenType.LeftParen) ? | true => {
        p.advance()
        expr := p.parse_expression()
        p.consume(TokenType.RightParen, "Expected ')'")
        return expr
    } | false => {}
    
    // Array literal
    p.check(TokenType.LeftBracket) ? | true => {
        p.advance()
        elements := vec_new<ast.Expression>()
        
        !p.check(TokenType.RightBracket) ? | true => {
            loop {
                elem := p.parse_expression()
                elements.push(elem)
                !p.match([TokenType.Comma]) ? | true => break | false => {}
            }
        } | false => {}
        
        p.consume(TokenType.RightBracket, "Expected ']'")
        return ast.Expression.Array(elements)
    } | false => {}
    
    // Struct literal
    p.check(TokenType.Identifier) && p.peek_next().type == TokenType.LeftBrace ? | true => {
        name := p.advance()
        p.consume(TokenType.LeftBrace, "Expected '{'")
        
        fields := vec_new<ast.FieldInit>()
        !p.check(TokenType.RightBrace) ? | true => {
            loop {
                field_name := p.consume(TokenType.Identifier, "Expected field name")
                p.consume(TokenType.Colon, "Expected ':'")
                value := p.parse_expression()
                
                fields.push(ast.FieldInit{
                    name: field_name.lexeme,
                    value: value,
                })
                
                !p.match([TokenType.Comma]) ? | true => break | false => {}
            }
        } | false => {}
        
        p.consume(TokenType.RightBrace, "Expected '}'")
        
        return ast.Expression.StructLiteral(ast.StructLiteral{
            name: name.lexeme,
            fields: fields,
        })
    } | false => {}
    
    p.error("Expected expression")
    return ast.Expression.Invalid
}

// Helper to peek at next token
parser_peek_next = (p:: Ptr<Parser>) Token {
    p.current + 1 < p.tokens.len() ?
        | true => return p.tokens.at(p.current + 1)
        | false => return Token{ type: TokenType.Eof }
}

// Public parsing function
parse = (source: string) ast.Program {
    // Tokenize the source
    tokens := lexer.tokenize(source)
    
    // Create parser
    parser := parser_new(tokens)
    
    // Parse program
    program := parse_program(&parser)
    
    // Report any errors
    parser.had_error ? | true => {
        io.println("\nParsing failed with $(parser.errors.len()) errors")
        range(0, parser.errors.len()).loop(i -> {
            error := parser.errors.at(i)
            io.println("  - $(error.message)")
        })
    } | false => {
        io.println("Parsing successful!")
    }
    
    return program
}