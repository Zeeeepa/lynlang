// Zen Standard Library: Testing Framework
// Simple but effective testing utilities

core := @std.core
io := @std.io

// Test result types
TestResult: Pass
    | Fail(reason: string)
    | Skip(reason: string)
    | Panic(message: string)

// Test case structure
TestCase: {
    name: string,
    test_fn: () TestResult,
    file: string,
    line: i32,
}

// Test suite structure
TestSuite: {
    name: string,
    tests: Vec<TestCase>,
    setup: Option<() void>,
    teardown: Option<() void>,
}

// Test runner state
TestRunner: {
    suites: Vec<TestSuite>,
    passed: i32,
    failed: i32,
    skipped: i32,
    panicked: i32,
    verbose: bool,
    stop_on_failure: bool,
}

// Global test runner
global_runner := TestRunner{
    suites: Vec<TestSuite>.new(),
    passed: 0,
    failed: 0,
    skipped: 0,
    panicked: 0,
    verbose: false,
    stop_on_failure: false,
}

// Create a new test suite
suite: (name: string) TestSuite  = {
    return TestSuite{
        name: name,
        tests: Vec<TestCase>.new(),
        setup: Option<() void>.None,
        teardown: Option<() void>.None,
    }
}

// Add a test to a suite
TestSuite.add_test = (self: *TestSuite, name: string, test_fn: () TestResult) void {
    test := TestCase{
        name: name,
        test_fn: test_fn,
        file: @std.file(),
        line: @std.line(),
    }
    self.tests.push(test)
}

// Set setup function for suite
TestSuite.set_setup = (self: *TestSuite, setup_fn: () void) void {
    self.setup = Option<() void>.Some(setup_fn)
}

// Set teardown function for suite
TestSuite.set_teardown = (self: *TestSuite, teardown_fn: () void) void {
    self.teardown = Option<() void>.Some(teardown_fn)
}

// Register a suite with the global runner
register_suite: (suite: TestSuite) void  = {
    global_runner.suites.push(suite)
}

// Assertion functions
assert: (condition: bool, message: string) TestResult  = {
    condition ?
        | true => return TestResult.Pass
        | false => return TestResult.Fail(message)
}

assert_eq = <T>(actual: T, expected: T, message: string) TestResult {
    actual == expected ?
        | true => return TestResult.Pass
        | false => {
            // Format error message
            msg := "Assertion failed: " + message + "\n  Expected: " + @std.str(expected) + "\n  Actual: " + @std.str(actual)
            return TestResult.Fail(msg)
        }
}

assert_ne = <T>(actual: T, expected: T, message: string) TestResult {
    actual != expected ?
        | true => return TestResult.Pass
        | false => {
            msg := "Assertion failed: " + message + "\n  Values should not be equal: " + @std.str(actual)
            return TestResult.Fail(msg)
        }
}

assert_lt = <T>(actual: T, expected: T, message: string) TestResult {
    actual < expected ?
        | true => return TestResult.Pass
        | false => {
            msg := "Assertion failed: " + message + "\n  " + @std.str(actual) + " should be less than " + @std.str(expected)
            return TestResult.Fail(msg)
        }
}

assert_le = <T>(actual: T, expected: T, message: string) TestResult {
    actual <= expected ?
        | true => return TestResult.Pass
        | false => {
            msg := "Assertion failed: " + message + "\n  " + @std.str(actual) + " should be less than or equal to " + @std.str(expected)
            return TestResult.Fail(msg)
        }
}

assert_gt = <T>(actual: T, expected: T, message: string) TestResult {
    actual > expected ?
        | true => return TestResult.Pass
        | false => {
            msg := "Assertion failed: " + message + "\n  " + @std.str(actual) + " should be greater than " + @std.str(expected)
            return TestResult.Fail(msg)
        }
}

assert_ge = <T>(actual: T, expected: T, message: string) TestResult {
    actual >= expected ?
        | true => return TestResult.Pass
        | false => {
            msg := "Assertion failed: " + message + "\n  " + @std.str(actual) + " should be greater than or equal to " + @std.str(expected)
            return TestResult.Fail(msg)
        }
}

// Assert that a function panics
assert_panic = (fn: () void, message: string) TestResult {
    // This would need runtime support for panic catching
    // For now, return skip
    return TestResult.Skip("Panic assertions not yet implemented")
}

// Run a single test case
run_test: (test: TestCase, verbose: bool) TestResult  = {
    verbose ?
        | true => io.print("Running test: " + test.name + "...")
        | false => {}
    
    // Execute the test function
    result := test.test_fn()
    
    // Print result if verbose
    verbose ?
        | true => {
            match result {
                | Pass => io.print("  ✓ PASS")
                | Fail(reason) => io.print("  ✗ FAIL: " + reason)
                | Skip(reason) => io.print("  ⊘ SKIP: " + reason)
                | Panic(msg) => io.print("  ⚠ PANIC: " + msg)
            }
        }
        | false => {}
    
    return result
}

// Run a test suite
run_suite: (suite: TestSuite, runner: *TestRunner) void  = {
    io.println("\n=== Test Suite: " + suite.name + " ===")
    
    // Run setup if present
    match suite.setup {
        | Some(setup_fn) => setup_fn()
        | None => {}
    }
    
    // Run each test
    i := 0
    loop i < suite.tests.len() {
        test := suite.tests[i]
        result := run_test(test, runner.verbose)
        
        // Update statistics
        match result {
            | Pass => runner.passed = runner.passed + 1
            | Fail(reason) => {
                runner.failed = runner.failed + 1
                io.println("FAILED: " + test.name)
                io.println("  " + reason)
                io.println("  at " + test.file + ":" + @std.str(test.line))
                
                runner.stop_on_failure ?
                    | true => return
                    | false => {}
            }
            | Skip(_) => runner.skipped = runner.skipped + 1
            | Panic(msg) => {
                runner.panicked = runner.panicked + 1
                io.println("PANIC: " + test.name)
                io.println("  " + msg)
                return  // Always stop on panic
            }
        }
        
        i = i + 1
    }
    
    // Run teardown if present
    match suite.teardown {
        | Some(teardown_fn) => teardown_fn()
        | None => {}
    }
}

// Run all registered test suites
run_all_tests: () i32  = {
    io.println("=== Running Zen Tests ===")
    
    // Reset statistics
    global_runner.passed = 0
    global_runner.failed = 0
    global_runner.skipped = 0
    global_runner.panicked = 0
    
    // Run each suite
    i := 0
    loop i < global_runner.suites.len() {
        suite := global_runner.suites[i]
        run_suite(suite, &global_runner)
        
        global_runner.panicked > 0 ?
            | true => break  // Stop if any test panicked
            | false => {}
        
        i = i + 1
    }
    
    // Print summary
    io.println("\n=== Test Summary ===")
    io.println("Passed:  " + @std.str(global_runner.passed))
    io.println("Failed:  " + @std.str(global_runner.failed))
    io.println("Skipped: " + @std.str(global_runner.skipped))
    io.println("Panicked: " + @std.str(global_runner.panicked))
    
    total := global_runner.passed + global_runner.failed + global_runner.skipped + global_runner.panicked
    io.println("Total:   " + @std.str(total))
    
    // Return exit code (0 for success, 1 for failure)
    global_runner.failed > 0 || global_runner.panicked > 0 ?
        | true => return 1
        | false => return 0
}

// Convenience macro-like functions for test definition
test = (name: string, test_fn: () TestResult) void {
    // Add test to the current suite
    // This would need compiler support to track current suite
    test_case := TestCase{
        name: name,
        test_fn: test_fn,
        file: @std.file(),
        line: @std.line(),
    }
    // For now, create a default suite
    default_suite := suite("default")
    default_suite.add_test(name, test_fn)
    register_suite(default_suite)
}

// Benchmark support
Benchmark: {
    name: string,
    iterations: i64,
    total_time: f64,
    min_time: f64,
    max_time: f64,
    avg_time: f64,
}

// Run a benchmark
benchmark = (name: string, iterations: i64, bench_fn: () void) Benchmark {
    extern clock = () f64  // Assuming we have a clock function
    
    io.println("Benchmarking: " + name)
    
    min_time := 999999999.0
    max_time := 0.0
    total_time := 0.0
    
    i := 0
    loop i < iterations {
        start := clock()
        bench_fn()
        end := clock()
        
        elapsed := end - start
        total_time = total_time + elapsed
        
        elapsed < min_time ?
            | true => { min_time = elapsed }
            | false => {}
        
        elapsed > max_time ?
            | true => { max_time = elapsed }
            | false => {}
        
        i = i + 1
    }
    
    avg_time := total_time / (iterations as f64)
    
    // Print results
    io.println("  Iterations: " + @std.str(iterations))
    io.println("  Total time: " + @std.str(total_time) + " seconds")
    io.println("  Average:    " + @std.str(avg_time) + " seconds")
    io.println("  Min:        " + @std.str(min_time) + " seconds")
    io.println("  Max:        " + @std.str(max_time) + " seconds")
    
    return Benchmark{
        name: name,
        iterations: iterations,
        total_time: total_time,
        min_time: min_time,
        max_time: max_time,
        avg_time: avg_time,
    }
}

// Example test usage (would be in separate test files)
example_test_suite: () void  = {
    s := suite("Example Tests")
    
    s.add_test("basic assertion", () TestResult {
        return assert(1 + 1 == 2, "Math is broken!")
    })
    
    s.add_test("equality assertion", () TestResult {
        return assert_eq(2 * 3, 6, "Multiplication failed")
    })
    
    s.add_test("comparison assertion", () TestResult {
        return assert_lt(5, 10, "5 should be less than 10")
    })
    
    register_suite(s)
}