// Zen Standard Library: Task (Stackful Coroutines)
// No FFI - uses compiler.syscall* intrinsics
//
// A Task is a suspendable computation. Tasks enable Zen's "allocator determines
// sync/async" model by allowing code to yield when using AsyncAllocator.
//
// Key design:
// - Each Task has its own stack (allocated via mmap)
// - Context switching saves/restores registers
// - Tasks can suspend at I/O points and resume later
// - The Scheduler manages runnable tasks

{ compiler } = @std
{ Result } = @std.core.result
{ Option } = @std.core.option
{ Allocator } = @std.memory.allocator
{ SYS_MMAP, SYS_MPROTECT, SYS_MUNMAP } = @std.sys.syscall

// ============================================================================
// Task State
// ============================================================================

TaskState:
    Created,     // Task created but not yet started
    Running,     // Currently executing
    Suspended,   // Waiting for I/O or other event
    Completed,   // Finished execution
    Failed       // Exited with error

// ============================================================================
// Task Context (CPU State)
// ============================================================================
// x86-64 context: callee-saved registers + stack pointer + instruction pointer
// We save: rbx, rbp, r12, r13, r14, r15, rsp, rip

TaskContext: {
    rsp: u64,    // Stack pointer
    rbp: u64,    // Base pointer
    rbx: u64,    // Callee-saved
    r12: u64,
    r13: u64,
    r14: u64,
    r15: u64,
    rip: u64     // Instruction pointer (return address)
}

// ============================================================================
// Task
// ============================================================================

// Default task stack size: 64KB
TASK_STACK_SIZE = 65536

// Guard page size: 4KB
GUARD_PAGE_SIZE = 4096

Task: {
    id: u64,
    state: TaskState,
    context: TaskContext,
    stack_base: i64,     // Bottom of stack allocation (mmap base)
    stack_size: usize,   // Total stack size including guard
    stack_top: i64,      // Top of usable stack
    entry_fn: i64,       // Entry point function
    entry_arg: i64,      // Argument to entry function
    result: i64,         // Result value (set on completion)
    allocator: Allocator
}

// ============================================================================
// Task Creation
// ============================================================================

Task.new = (entry: i64, arg: i64, allocator: Allocator) Result<Task, i32> {
    total_size = TASK_STACK_SIZE + GUARD_PAGE_SIZE

    // Allocate stack with guard page
    stack_base = compiler.syscall6(
        SYS_MMAP,
        0,
        total_size,
        3,   // PROT_READ | PROT_WRITE
        34,  // MAP_PRIVATE | MAP_ANONYMOUS
        -1,
        0
    )
    stack_base < 0 ? {
        return Result.Err((0 - stack_base) as i32)
    }

    // Set guard page (bottom of stack) to no-access
    compiler.syscall3(
        SYS_MPROTECT,
        stack_base,
        GUARD_PAGE_SIZE,
        0    // PROT_NONE
    )

    // Stack grows down, so top is base + size
    stack_top = stack_base + total_size as i64 - 8

    // Initialize context for first switch
    // Set up stack so context_switch will jump to task_entry
    initial_rsp = stack_top - 64  // Space for initial frame

    task = Task {
        id: 0,  // Will be set by scheduler
        state: TaskState.Created,
        context: TaskContext {
            rsp: initial_rsp as u64,
            rbp: 0,
            rbx: 0,
            r12: 0,
            r13: 0,
            r14: 0,
            r15: 0,
            rip: task_entry_trampoline as u64
        },
        stack_base: stack_base,
        stack_size: total_size,
        stack_top: stack_top,
        entry_fn: entry,
        entry_arg: arg,
        result: 0,
        allocator: allocator
    }

    // Store task pointer and arg on initial stack for trampoline
    compiler.store<i64>(compiler.int_to_ptr(initial_rsp), &task.ref() as i64)
    compiler.store<i64>(compiler.int_to_ptr(initial_rsp + 8), arg)

    return Result.Ok(task)
}

// ============================================================================
// Task Entry Trampoline
// ============================================================================
// Called when a task first starts executing.
// Reads task pointer from stack, calls actual entry function.

task_entry_trampoline = () void {
    // Get task pointer from stack (set up in Task.new)
    // This is architecture-specific - we need inline assembly here
    // For now, use a simplified model where entry is called directly

    // In a real implementation, this would:
    // 1. Read task pointer from known stack location
    // 2. Call task.entry_fn(task.entry_arg)
    // 3. Mark task as Completed
    // 4. Yield to scheduler

    compiler.trap()  // Placeholder - real impl needs asm
}

// ============================================================================
// Context Switching
// ============================================================================
// Low-level context switch between tasks.
// Saves current context, loads new context.
//
// This MUST be implemented in assembly for correctness.
// The function signature is:
//   context_switch(old: Ptr<TaskContext>, new: Ptr<TaskContext>)

// For now, provide a stub that documents what needs to happen
context_switch = (old_ctx: i64, new_ctx: i64) void {
    // In assembly, this would:
    //
    // 1. Save callee-saved registers to old_ctx:
    //    mov [old_ctx + 0], rsp
    //    mov [old_ctx + 8], rbp
    //    mov [old_ctx + 16], rbx
    //    mov [old_ctx + 24], r12
    //    mov [old_ctx + 32], r13
    //    mov [old_ctx + 40], r14
    //    mov [old_ctx + 48], r15
    //    lea rax, [rip + .return_point]
    //    mov [old_ctx + 56], rax
    //
    // 2. Load registers from new_ctx:
    //    mov rsp, [new_ctx + 0]
    //    mov rbp, [new_ctx + 8]
    //    mov rbx, [new_ctx + 16]
    //    mov r12, [new_ctx + 24]
    //    mov r13, [new_ctx + 32]
    //    mov r14, [new_ctx + 40]
    //    mov r15, [new_ctx + 48]
    //    jmp [new_ctx + 56]
    //
    // .return_point:
    //    ret

    // Stub implementation - will be replaced with intrinsic
    compiler.trap()
}

// ============================================================================
// Task Methods
// ============================================================================

// Suspend the current task (yield to scheduler)
Task.suspend = (self: MutPtr<Task>) void {
    self.val.state = TaskState.Suspended
    // Scheduler will handle actual context switch
}

// Resume a suspended task
Task.resume = (self: MutPtr<Task>) void {
    self.val.state == TaskState.Suspended ? {
        self.val.state = TaskState.Running
    }
}

// Check if task is completed
Task.is_done = (self: Ptr<Task>) bool {
    return self.val.state == TaskState.Completed ||
           self.val.state == TaskState.Failed
}

// Get task result (after completion)
Task.get_result = (self: Ptr<Task>) Option<i64> {
    self.val.state == TaskState.Completed ? {
        return Option.Some(self.val.result)
    }
    return Option.None
}

// ============================================================================
// Task Cleanup
// ============================================================================

Task.destroy = (self: MutPtr<Task>) void {
    // Unmap stack
    total_size = self.val.stack_size
    compiler.syscall2(SYS_MUNMAP, self.val.stack_base, total_size)
}

// ============================================================================
// Current Task
// ============================================================================
// Thread-local storage for current task pointer.
// In a real implementation, this would use the FS segment register on x86-64.

// Global current task pointer (simple model, not thread-safe)
// Real implementation would use TLS
CURRENT_TASK: i64 = 0

set_current_task = (task: i64) void {
    CURRENT_TASK = task
}

get_current_task = () Option<MutPtr<Task>> {
    CURRENT_TASK == 0 ? { return Option.None }
    return Option.Some(compiler.int_to_ptr(CURRENT_TASK) as MutPtr<Task>)
}

// ============================================================================
// Await Point
// ============================================================================
// This is the key function that enables sync/async transparency.
// When called with a pending operation, it:
// - In sync mode: blocks until complete
// - In async mode: suspends task, returns when resumed

await_completion = (op_id: u64) void {
    // Check if we're in a task context
    task_opt = get_current_task()
    task_opt ? {
        | None {
            // No task context - we're in sync mode
            // Blocking is handled by the operation itself
        }
        | Some(task) {
            // We're in a task - suspend until op completes
            task.suspend()
            // Scheduler will resume us when op_id completes
        }
    }
}
