// Concurrent Programming Patterns
// Demonstrating Zen's approach to safe concurrency

{ io, Result } = @std
{ Channel, spawn, AtomicU32, AtomicBool, Mutex } = @std.concurrent
{ Vec } = @std.collections

// === Worker Pool Pattern ===
WorkerPool<T, R>: {
    workers: u32,
    tasks: Channel<T>,
    results: Channel<Result<R, string>>,
    shutdown: AtomicBool
}

WorkerPool.new = (workers: u32) WorkerPool<T, R> {
    WorkerPool {
        workers: workers,
        tasks: Channel<T>.new(workers * 2),
        results: Channel<Result<R, string>>.new(workers * 2),
        shutdown: AtomicBool.new(false)
    }
}

WorkerPool.start = (self, processor: (T) Result<R, string>) void {
    for id in 0..self.workers {
        spawn(async () => {
            loop {
                self.shutdown.load(.SeqCst) ?
                    | true { break }
                    | false {}
                
                self.tasks.receive() ?
                    | Some -> task {
                        result := processor(task)
                        self.results.send(result)
                    }
                    | None { break }
            }
        })
    }
}

WorkerPool.submit = async (self, task: T) void {
    await self.tasks.send(task)
}

WorkerPool.stop = (self) void {
    self.shutdown.store(true, .SeqCst)
    self.tasks.close()
}

// === Rate Limiter Pattern ===
RateLimiter: {
    tokens: AtomicU32,
    max_tokens: u32,
    refill_rate: u32,  // tokens per second
    last_refill: AtomicU64
}

RateLimiter.new = (max_tokens: u32, refill_rate: u32) RateLimiter {
    RateLimiter {
        tokens: AtomicU32.new(max_tokens),
        max_tokens: max_tokens,
        refill_rate: refill_rate,
        last_refill: AtomicU64.new(current_time_ms())
    }
}

RateLimiter.acquire = async (self) bool {
    // Refill tokens based on elapsed time
    now := current_time_ms()
    last := self.last_refill.load(.SeqCst)
    elapsed := (now - last) / 1000  // Convert to seconds
    
    elapsed > 0 ?
        | true {
            new_tokens := elapsed * self.refill_rate
            current := self.tokens.load(.SeqCst)
            updated := min(current + new_tokens, self.max_tokens)
            self.tokens.store(updated, .SeqCst)
            self.last_refill.store(now, .SeqCst)
        }
        | false {}
    
    // Try to acquire a token
    loop {
        current := self.tokens.load(.SeqCst)
        current > 0 ?
            | true {
                self.tokens.compare_exchange(current, current - 1, .SeqCst, .SeqCst) ?
                    | Ok { return true }
                    | Err { continue }
            }
            | false { return false }
    }
}

// === Pub/Sub Pattern ===
PubSub<T>: {
    subscribers: Mutex<Vec<Channel<T>>>,
    topic: string
}

PubSub.new = (topic: string) PubSub<T> {
    PubSub {
        subscribers: Mutex.new(Vec<Channel<T>>.new()),
        topic: topic
    }
}

PubSub.subscribe = async (self) Channel<T> {
    ch := Channel<T>.new(100)
    await self.subscribers.lock()
    self.subscribers.value.push(ch.clone())
    self.subscribers.unlock()
    return ch
}

PubSub.publish = async (self, message: T) void {
    await self.subscribers.lock()
    for sub in self.subscribers.value {
        spawn(async () => {
            await sub.send(message.clone())
        })
    }
    self.subscribers.unlock()
}

// === Demo Application ===
main = async () void {
    io.println("=== Advanced Concurrency Patterns ===\n")
    
    // Worker Pool Demo
    io.println("1. Worker Pool Pattern")
    pool := WorkerPool<i32, i32>.new(4)
    
    processor = (n: i32) Result<i32, string> {
        // Simulate work
        Result.Ok(n * n)
    }
    
    pool.start(processor)
    
    // Submit tasks
    for i in 0..10 {
        await pool.submit(i)
    }
    
    // Collect results
    mut results := Vec<i32>.new()
    for _ in 0..10 {
        pool.results.receive() ?
            | Some -> result {
                result ?
                    | Ok -> val { results.push(val) }
                    | Err -> e { io.println("Error: ${e}") }
            }
            | None {}
    }
    
    io.println("Processed: ${results}")
    pool.stop()
    
    // Rate Limiter Demo
    io.println("\n2. Rate Limiter Pattern")
    limiter := RateLimiter.new(5, 2)  // 5 tokens, 2 per second
    
    mut allowed := 0
    mut denied := 0
    for _ in 0..10 {
        await limiter.acquire() ?
            | true { allowed += 1 }
            | false { denied += 1 }
    }
    
    io.println("Allowed: ${allowed}, Denied: ${denied}")
    
    // Pub/Sub Demo
    io.println("\n3. Pub/Sub Pattern")
    events := PubSub<string>.new("events")
    
    // Create subscribers
    sub1 := await events.subscribe()
    sub2 := await events.subscribe()
    
    // Spawn listeners
    spawn(async () => {
        loop {
            sub1.receive() ?
                | Some -> msg { io.println("  Sub1: ${msg}") }
                | None { break }
        }
    })
    
    spawn(async () => {
        loop {
            sub2.receive() ?
                | Some -> msg { io.println("  Sub2: ${msg}") }
                | None { break }
        }
    })
    
    // Publish messages
    await events.publish("Hello subscribers!")
    await events.publish("Concurrent message")
    
    // Give time for processing
    sleep_ms(100)
    
    io.println("\nConcurrency patterns complete!")
}