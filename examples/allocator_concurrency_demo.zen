// Colorless Concurrency in Zen - Functions take allocators as parameters
// to control execution mode (synchronous vs concurrent)

io {  } = @std.io
net {  } = @std.net
fs {  } = @std.fs

// Allocator trait - memory + execution context
// Explicit allocator parameters control execution mode
Allocator: {
    // Memory operations
    alloc: (size: usize) *void
    free: (ptr: *void) void
    
    // Execution mode flag
    is_concurrent: bool
    
    // Continuation support (for concurrent execution)
    suspend: () ?Continuation
    resume: (cont: Continuation) void
}

// Synchronous allocator - blocking I/O
SyncAllocator: Allocator = {
    is_concurrent: false,
    alloc: (size) => std.heap.alloc(size),
    free: (ptr) => std.heap.free(ptr),
    suspend: () => null,  // Can't suspend in sync mode
    resume: (_) => @panic("Cannot resume in sync context")
}

// Concurrent allocator - non-blocking I/O
ConcurrentAllocator: Allocator = {
    is_concurrent: true,
    runtime: Runtime.init(),
    alloc: (size) => runtime.heap.alloc(size),
    free: (ptr) => runtime.heap.free(ptr),
    suspend: () => runtime.save_continuation(),
    resume: (cont) => runtime.schedule(cont)
}

// Functions are colorless - allocator determines behavior
read_file = (path: String, alloc: *Allocator) Result<[]u8, io.Error>  {
    // Allocate buffer using provided allocator
    buffer := alloc.alloc(4096)
    defer alloc.free(buffer)
    
    // Open file - blocks or yields based on allocator
    fd := fs.open(path, alloc)?
    defer fs.close(fd)
    
    // Read file - execution mode depends on allocator
    bytes_read := alloc.is_concurrent ?
        | true { { }
            // Concurrent path: suspend and resume
            cont := alloc.suspend()
            io.read_concurrent(fd, buffer, cont)
            alloc.runtime.wait()
        }
        | false { { }
            // Sync path: just block
            io.read_sync(fd, buffer)
        }
    
    .Ok(buffer[0..bytes_read])
}

// HTTP handler - colorless function
handle_request = (req: HttpRequest, alloc: *Allocator) Result<HttpResponse, Error>  {
    // Pattern match routes
    response := req.path ?
        | "/users" { fetch_users(alloc)? }
        | "/posts" { fetch_posts(alloc)? }
        | "/api/data" { { }
            // Read from file - colorless!
            data := read_file("data.json", alloc)?
            HttpResponse.json(data)
        }
        | _ { HttpResponse.not_found() }
    
    .Ok(response)
}

// Database operations - colorless
query_database = (query: String, alloc: *Allocator) Result<[]Row, Error>  {
    // Connect to database
    conn := db.connect("postgres://localhost/mydb", alloc)?
    defer conn.close()
    
    // Execute query - sync or concurrent based on allocator
    rows := alloc.is_concurrent ?
        | true { conn.execute_concurrent(query, alloc)? }
        | false { conn.execute_sync(query)? }
    
    .Ok(rows)
}

// Web server - colorless server
run_server = (port: u16, alloc: *Allocator) Result<void, Error>  {
    io.println("Starting server on port $(port)")
    io.println("Mode: $(alloc.is_concurrent ? \"concurrent\" : \"synchronous\")")
    
    // Create listener
    listener := net.listen(port, alloc)?
    
    loop {
        // Accept connections - blocks or yields based on allocator
        client_result := listener.accept(alloc)
        
        client_result ?
            | .Ok -> client { { }
                // Spawn handler task
                spawn_task(() => {
                    result := handle_client(client, alloc)
                    result ?
                        | .Ok -> _ { io.println("Client handled successfully") }
                        | .Err -> e { io.println("Client error: $(e)") }
                }, alloc)
            }
            | .Err -> e { { }
                io.println("Accept error: $(e)")
                break
            }
    }
    
    .Ok(())
}

// Client handler
handle_client = (client: Connection, alloc: *Allocator) Result<void, Error>  {
    // Read request
    request := read_request(client, alloc)?
    
    // Process request
    response := handle_request(request, alloc)?
    
    // Send response
    send_response(client, response, alloc)?
    
    .Ok(())
}

// Task spawning based on allocator
spawn_task = (task: () void, alloc: *Allocator) void  {
    alloc.is_concurrent ?
        | true { { }
            // Spawn as green thread/fiber
            alloc.runtime.spawn_fiber(task)
        }
        | false { { }
            // Execute immediately in sync mode
            task()
        }
}

// Pipeline processing - colorless!
process_pipeline = (input: String, alloc: *Allocator) Result<String, Error>  {
    // Each step uses the same allocator
    parsed := parse_data(input, alloc)?
    validated := validate(parsed, alloc)?
    transformed := transform(validated, alloc)?
    formatted := format_output(transformed, alloc)?
    
    .Ok(formatted)
}

// Main demonstrates different execution modes
main = () i32  {
    io.println("=== Colorless Concurrency Demo ===")
    io.println("Allocators control execution mode")
    io.println("Functions are colorless - same code for sync and concurrent\n")
    
    // Development mode: synchronous for easy debugging
    debug_mode := @compileVar("DEBUG")
    
    debug_mode ?
        | true { { }
            io.println("Running in SYNC mode (debug)")
            sync_alloc := SyncAllocator{}
            run_demo(&sync_alloc)
        }
        | false { { }
            io.println("Running in CONCURRENT mode (production)")
            concurrent_alloc := ConcurrentAllocator{ runtime: Runtime.init() }
            run_demo(&concurrent_alloc)
        }
    
    0
}

// Demo function that works with any allocator
run_demo = (alloc: *Allocator) void  {
    io.println("\n1. Reading files...")
    file_result := read_file("test.txt", alloc)
    file_result ?
        | .Ok -> data { io.println("Read $(data.len) bytes") }
        | .Err -> e { io.println("File error: $(e)") }
    
    io.println("\n2. Database query...")
    db_result := query_database("SELECT * FROM users", alloc)
    db_result ?
        | .Ok -> rows { io.println("Found $(rows.len) rows") }
        | .Err -> e { io.println("DB error: $(e)") }
    
    io.println("\n3. Processing pipeline...")
    pipeline_result := process_pipeline("input data", alloc)
    pipeline_result ?
        | .Ok -> output { io.println("Pipeline output: $(output)") }
        | .Err -> e { io.println("Pipeline error: $(e)") }
    
    io.println("\n4. Starting server...")
    server_result := run_server(8080, alloc)
    server_result ?
        | .Ok -> _ { io.println("Server stopped gracefully") }
        | .Err -> e { io.println("Server error: $(e)") }
}

// Testing with sync allocator for determinism
test "database operations" {
    // Tests always use sync allocator for deterministic behavior
    test_alloc := TestAllocator{}
    
    // No concurrent complexity in tests!
    conn := db.connect("test.db", &test_alloc)
    result := conn.execute("INSERT INTO users VALUES (1, 'Alice')", &test_alloc)
    
    result ?
        | .Ok -> _ { assert(true) }
        | .Err -> e { assert(false, "Database error: $(e)") }
    
    // Check for memory leaks
    assert(test_alloc.bytes_leaked() == 0)
}

// Progressive enhancement example
enhanced_main = () void  {
    // Start simple with sync
    io.println("Phase 1: Synchronous execution")
    sync_alloc := SyncAllocator{}
    simple_task(&sync_alloc)
    
    // Add concurrency when needed
    io.println("\nPhase 2: Concurrent execution")
    concurrent_alloc := ConcurrentAllocator{ runtime: Runtime.init() }
    simple_task(&concurrent_alloc)  // Same code, now concurrent!
    
    // Mix modes for optimization
    io.println("\nPhase 3: Mixed execution")
    
    // I/O bound: use concurrent
    io_data := fetch_remote_data(&concurrent_alloc)
    
    // CPU bound: use sync
    result := heavy_computation(io_data, &sync_alloc)
    
    // They work together seamlessly!
    io.println("Result: $(result)")
}

// Helper types and functions (stubs for demo)
HttpRequest: { path: String, method: String, body: String }
HttpResponse: { status: u32, body: String }
HttpResponse.json: (data: []u8) HttpResponse = HttpResponse{ status: 200, body: "json" }
HttpResponse.not_found: () HttpResponse = HttpResponse{ status: 404, body: "Not Found" }

Connection: {}
Row: { data: String }
Runtime: { heap: Heap }
Runtime.init: () Runtime = Runtime{ heap: Heap{} }
Runtime.spawn_fiber = (task: () void) void  {}
Runtime.save_continuation: () Continuation = Continuation{}
Runtime.schedule = (cont: Continuation) void  {}
Runtime.wait = () void  {}

Continuation: {}
Heap: {}
Heap.alloc: (size: usize) *void = @std.heap.alloc(size)
Heap.free: (ptr: *void) void = @std.heap.free(ptr)

Error: { message: String }

db: {}
db.connect: (url: String, alloc: *Allocator) Result<Connection, Error> = .Ok(Connection{})
Connection.close = () void  {}
Connection.execute_sync: (query: String) Result<[]Row, Error> = .Ok([])
Connection.execute_concurrent: (query: String, alloc: *Allocator) Result<[]Row, Error> = .Ok([])

fetch_users: (alloc: *Allocator) Result<HttpResponse, Error> = .Ok(HttpResponse.json([]))
fetch_posts: (alloc: *Allocator) Result<HttpResponse, Error> = .Ok(HttpResponse.json([]))
read_request = (client: Connection, alloc: *Allocator) Result<HttpRequest, Error>  {
    .Ok(HttpRequest{ path: "/", method: "GET", body: "" })
}
send_response: (client: Connection, response: HttpResponse, alloc: *Allocator) Result<void, Error> = .Ok(())

parse_data: (input: String, alloc: *Allocator) Result<String, Error> = .Ok(input)
validate: (data: String, alloc: *Allocator) Result<String, Error> = .Ok(data)
transform: (data: String, alloc: *Allocator) Result<String, Error> = .Ok(data)
format_output: (data: String, alloc: *Allocator) Result<String, Error> = .Ok(data)

simple_task = (alloc: *Allocator) void  {
    io.println("Task executed with allocator mode: $(alloc.is_concurrent ? \"concurrent\" : \"sync\")")
}

fetch_remote_data: (alloc: *Allocator) String = "remote data"
heavy_computation: (data: String, alloc: *Allocator) String = "computed: $(data)"

TestAllocator: Allocator = {
    is_concurrent: false,
    alloc: std.heap.alloc,
    free: std.heap.free,
    suspend: () => null,
    resume: (_) => {},
    bytes_leaked: () u64 = 0
}