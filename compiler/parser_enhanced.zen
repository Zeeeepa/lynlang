// Enhanced Zen Parser for Self-Hosting
// Complete AST generation for all Zen language features

io := @std.io
string := @std.string
vec := @std.vec
core := @std.core
lexer := @compiler.lexer_enhanced

// AST Node Types
AstNodeType = |
    // Declarations
    FunctionDecl,
    VariableDecl,
    StructDecl,
    EnumDecl,
    TraitDecl,
    ImplBlock,
    TypeAlias,
    
    // Statements
    ExpressionStmt,
    ReturnStmt,
    BreakStmt,
    ContinueStmt,
    LoopStmt,
    BlockStmt,
    
    // Expressions
    BinaryExpr,
    UnaryExpr,
    CallExpr,
    MemberExpr,
    IndexExpr,
    IdentifierExpr,
    LiteralExpr,
    MatchExpr,
    IfExpr,
    ComptimeExpr,
    
    // Types
    NamedType,
    PointerType,
    ArrayType,
    FunctionType,
    GenericType,

// AST Node
AstNode = struct {
    type: AstNodeType,
    data: AstData,
    line: u32,
    column: u32,
}

// AST Data variants
AstData = |
    FunctionDecl -> {
        name: string,
        params: vec.Vec<Parameter>,
        return_type: *Type,
        body: *AstNode,
        is_generic: bool,
    },
    VariableDecl -> {
        name: string,
        type: *Type,
        value: *AstNode,
        is_mutable: bool,
    },
    StructDecl -> {
        name: string,
        fields: vec.Vec<Field>,
        generics: vec.Vec<string>,
    },
    EnumDecl -> {
        name: string,
        variants: vec.Vec<EnumVariant>,
        generics: vec.Vec<string>,
    },
    BinaryExpr -> {
        left: *AstNode,
        operator: BinaryOp,
        right: *AstNode,
    },
    UnaryExpr -> {
        operator: UnaryOp,
        operand: *AstNode,
    },
    CallExpr -> {
        callee: *AstNode,
        args: vec.Vec<*AstNode>,
    },
    MemberExpr -> {
        object: *AstNode,
        member: string,
    },
    IdentifierExpr -> {
        name: string,
    },
    LiteralExpr -> {
        value: LiteralValue,
    },
    BlockStmt -> {
        statements: vec.Vec<*AstNode>,
    },
    ReturnStmt -> {
        value: Option<*AstNode>,
    },
    LoopStmt -> {
        condition: Option<*AstNode>,
        body: *AstNode,
    },
    MatchExpr -> {
        value: *AstNode,
        arms: vec.Vec<MatchArm>,
    },

// Type representation
Type = |
    Named -> name: string,
    Pointer -> inner: *Type,
    Array -> element: *Type,
    FixedArray -> { element: *Type, size: u32 },
    Function -> { params: vec.Vec<*Type>, ret: *Type },
    Generic -> { base: string, args: vec.Vec<*Type> },
    Primitive -> kind: PrimitiveKind,

// Primitive types
PrimitiveKind = |
    I8, I16, I32, I64,
    U8, U16, U32, U64,
    F32, F64,
    Bool, Char, String,
    Void,

// Binary operators
BinaryOp = |
    Add, Sub, Mul, Div, Mod,
    Equal, NotEqual, Less, Greater, LessEqual, GreaterEqual,
    And, Or,
    Assign,

// Unary operators
UnaryOp = |
    Not, Negate, Deref, AddressOf,

// Literal values
LiteralValue = |
    Number -> value: string,
    String -> value: string,
    Char -> value: char,
    Bool -> value: bool,
    Null,

// Function parameter
Parameter = struct {
    name: string,
    type: *Type,
    is_mutable: bool,
}

// Struct field
Field = struct {
    name: string,
    type: *Type,
}

// Enum variant
EnumVariant = struct {
    name: string,
    data: Option<vec.Vec<Field>>,
}

// Match arm
MatchArm = struct {
    pattern: *Pattern,
    guard: Option<*AstNode>,
    body: *AstNode,
}

// Pattern for match expressions
Pattern = |
    Wildcard,
    Identifier -> name: string,
    Literal -> value: LiteralValue,
    Struct -> { name: string, fields: vec.Vec<FieldPattern> },
    Enum -> { name: string, variant: string, fields: Option<vec.Vec<*Pattern>> },

// Field pattern for struct destructuring
FieldPattern = struct {
    name: string,
    pattern: *Pattern,
}

// Parser state
Parser = struct {
    tokens: vec.Vec<lexer.Token>,
    current: u32,
    errors: vec.Vec<string>,
}

// Create a new parser
parser_new = (tokens: vec.Vec<lexer.Token>) Parser {
    return Parser{
        tokens: tokens,
        current: 0,
        errors: vec.new<string>(),
    }
}

// Parse tokens into AST
parse = (p: *Parser) Result<vec.Vec<*AstNode>, vec.Vec<string>> {
    nodes := vec.new<*AstNode>()
    
    loop !is_at_end(p) {
        match parse_declaration(p) {
            | Ok -> node => nodes.push(node)
            | Err -> msg => {
                p.errors.push(msg)
                synchronize(p)
            }
        }
    }
    
    p.errors.is_empty() ? 
        { return Result.Ok(nodes) } : 
        { return Result.Err(p.errors) }
}

// Parse a declaration
parse_declaration = (p: *Parser) Result<*AstNode, string> {
    current := peek(p)
    
    match current.type {
        | lexer.TokenType.Struct => parse_struct(p)
        | lexer.TokenType.Enum => parse_enum(p)
        | lexer.TokenType.Trait => parse_trait(p)
        | lexer.TokenType.Impl => parse_impl(p)
        | lexer.TokenType.Type => parse_type_alias(p)
        | lexer.TokenType.Const | lexer.TokenType.Let => parse_variable(p)
        | lexer.TokenType.Identifier -> _ => {
            // Could be variable declaration or expression
            peek_ahead(p, 1).type == lexer.TokenType.ColonEqual ||
            peek_ahead(p, 1).type == lexer.TokenType.ColonColonEqual ?
                { parse_variable(p) } : { parse_statement(p) }
        }
        | _ => parse_statement(p)
    }
}

// Parse function declaration
parse_function = (p: *Parser) Result<*AstNode, string> {
    start_token := advance(p) // consume identifier
    
    // Parse function name
    name := start_token.lexeme
    
    // Parse = 
    consume(p, lexer.TokenType.Assign, "Expected '=' after function name")?
    
    // Parse parameters
    consume(p, lexer.TokenType.LeftParen, "Expected '(' for parameters")?
    params := parse_parameters(p)?
    consume(p, lexer.TokenType.RightParen, "Expected ')' after parameters")?
    
    // Parse return type
    return_type := parse_type(p)?
    
    // Parse body
    body := parse_block(p)?
    
    return Result.Ok(AstNode{
        type: AstNodeType.FunctionDecl,
        data: AstData.FunctionDecl -> {
            name: name,
            params: params,
            return_type: return_type,
            body: body,
            is_generic: false,
        },
        line: start_token.line,
        column: start_token.column,
    })
}

// Parse struct declaration
parse_struct = (p: *Parser) Result<*AstNode, string> {
    start_token := advance(p) // consume 'struct' or identifier
    
    name := start_token.type == lexer.TokenType.Struct ?
        { consume(p, lexer.TokenType.Identifier, "Expected struct name")?.lexeme } :
        { start_token.lexeme }
    
    // Parse generics if present
    generics := vec.new<string>()
    check(p, lexer.TokenType.Less) ? {
        generics = parse_generic_params(p)?
    } : {}
    
    // Parse = {
    consume(p, lexer.TokenType.Assign, "Expected '=' after struct name")?
    consume(p, lexer.TokenType.LeftBrace, "Expected '{' for struct body")?
    
    // Parse fields
    fields := vec.new<Field>()
    loop !check(p, lexer.TokenType.RightBrace) && !is_at_end(p) {
        field_name := consume(p, lexer.TokenType.Identifier, "Expected field name")?.lexeme
        consume(p, lexer.TokenType.Colon, "Expected ':' after field name")?
        field_type := parse_type(p)?
        
        fields.push(Field{
            name: field_name,
            type: field_type,
        })
        
        check(p, lexer.TokenType.Comma) ? { advance(p) } : {}
    }
    
    consume(p, lexer.TokenType.RightBrace, "Expected '}' after struct fields")?
    
    return Result.Ok(AstNode{
        type: AstNodeType.StructDecl,
        data: AstData.StructDecl -> {
            name: name,
            fields: fields,
            generics: generics,
        },
        line: start_token.line,
        column: start_token.column,
    })
}

// Helper functions

is_at_end = (p: *Parser) bool {
    return peek(p).type == lexer.TokenType.Eof
}

peek = (p: *Parser) lexer.Token {
    return p.tokens[p.current]
}

peek_ahead = (p: *Parser, n: u32) lexer.Token {
    idx := p.current + n
    idx >= p.tokens.len() ? 
        { return p.tokens[p.tokens.len() - 1] } : 
        { return p.tokens[idx] }
}

advance = (p: *Parser) lexer.Token {
    !is_at_end(p) ? { p.current = p.current + 1 } : {}
    return p.tokens[p.current - 1]
}

check = (p: *Parser, type: lexer.TokenType) bool {
    is_at_end(p) ? { return false } : { return peek(p).type == type }
}

consume = (p: *Parser, type: lexer.TokenType, message: string) Result<lexer.Token, string> {
    check(p, type) ? 
        { return Result.Ok(advance(p)) } : 
        { return Result.Err(message + " at line " + string.from_u32(peek(p).line)) }
}

synchronize = (p: *Parser) void {
    advance(p)
    
    loop !is_at_end(p) {
        previous(p).type == lexer.TokenType.Semicolon ? { return } : {}
        
        match peek(p).type {
            | lexer.TokenType.Struct | 
              lexer.TokenType.Enum | lexer.TokenType.Trait |
              lexer.TokenType.Type | lexer.TokenType.Const |
              lexer.TokenType.Let => return
            | _ => {}
        }
        
        advance(p)
    }
}

previous = (p: *Parser) lexer.Token {
    return p.tokens[p.current - 1]
}