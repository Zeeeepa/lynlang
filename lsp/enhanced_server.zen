// Enhanced Zen Language Server Protocol Implementation
// Provides advanced IDE support with hover, go-to-definition, and more

core = @std
io = @std
string = @std
{ Vec, DynVec } = @std
hashmap = @std
fs = @std
json = @std
result = @std

// Import compiler modules
lexer = @std
parser = @std
type_checker = @std
ast = @std

// Symbol information for tracking definitions and references
Symbol := {
    name: string
    kind: SymbolKind
    type_info: Option<ast.Type>
    definition_location: Location
    references: DynVec<Location>
    documentation: Option<string>
    signature: Option<string>
    parent: Option<string>  // Parent symbol for nested items
}

// Enhanced document with symbol table
EnhancedDocument := {
    uri: string
    version: i32
    content: string
    lines: DynVec<string>  // Split content for quick line access
    tokens: DynVec<lexer.Token>
    ast: Option<ast.Program>
    symbols: HashMap<string, Symbol>  // Symbol table
    imports: DynVec<ImportInfo>
    diagnostics: DynVec<Diagnostic>
    dirty: bool  // Needs reanalysis
}

// Import tracking
ImportInfo := {
    module_name: string
    alias: Option<string>
    location: Location
    resolved_path: Option<string>
}

// Enhanced Language Server
EnhancedLanguageServer := {
    initialized: bool
    root_uri: Option<string>
    capabilities: ServerCapabilities
    documents: HashMap<string, EnhancedDocument>
    global_symbols: HashMap<string, Symbol>  // Cross-file symbols
    workspace_symbols: DynVec<Symbol>  // All workspace symbols for search
    type_definitions: HashMap<string, ast.TypeDefinition>
    import_graph: HashMap<string, DynVec<string>>  // Import dependencies
}

// Position and location types (reuse from original)
Position := {
    line: u32
    character: u32
}

Range := {
    start: Position
    end: Position
}

Location := {
    uri: string
    range: Range
}

// Hover information
Hover := {
    contents: MarkupContent
    range: Option<Range>
}

MarkupContent := {
    kind: string  // "plaintext" or "markdown"
    value: string
}

// Symbol kinds
SymbolKind: File, Module, Namespace, Package, Class, Method, Property, Field, Constructor, Enum, Interface, Function, Variable, Constant, String, Number, Boolean, Array, Object, Key, Null, EnumMember, Struct, Event, Operator, TypeParameter

// Diagnostic types
Diagnostic := {
    range: Range
    severity: DiagnosticSeverity
    code: Option<string>
    source: string
    message: string
    tags: DynVec<DiagnosticTag>
    relatedInformation: DynVec<DiagnosticRelatedInformation>
}

DiagnosticSeverity: Error, Warning, Information, Hint

DiagnosticTag: Unnecessary, Deprecated

DiagnosticRelatedInformation := {
    location: Location
    message: string
}

// Create enhanced language server
create_enhanced_server = () EnhancedLanguageServer {
    return EnhancedLanguageServer{
        initialized: false,
        root_uri: None,
        capabilities: create_server_capabilities(),
        documents: hashmap.new<string, EnhancedDocument>(),
        global_symbols: hashmap.new<string, Symbol>(),
        workspace_symbols: DynVec.new<Symbol>(),
        type_definitions: hashmap.new<string, ast.TypeDefinition>(),
        import_graph: hashmap.new<string, DynVec<string>>()
    }
}

// Create server capabilities
create_server_capabilities = () ServerCapabilities {
    return ServerCapabilities{
        textDocumentSync: 1,  // Full sync
        completionProvider: CompletionOptions{
            triggerCharacters: DynVec.from([".", ":", "@", "/", "\""])
        },
        hoverProvider: true,
        definitionProvider: true,
        typeDefinitionProvider: true,
        implementationProvider: true,
        referencesProvider: true,
        documentHighlightProvider: true,
        documentSymbolProvider: true,
        workspaceSymbolProvider: true,
        codeActionProvider: true,
        codeLensProvider: CodeLensOptions{
            resolveProvider: true
        },
        documentFormattingProvider: true,
        documentRangeFormattingProvider: true,
        renameProvider: RenameOptions{
            prepareProvider: true
        },
        foldingRangeProvider: true,
        signatureHelpProvider: SignatureHelpOptions{
            triggerCharacters: DynVec.from(["(", ","])
        }
    }
}

// Analyze document and build symbol table
analyze_document = (server: Ptr<EnhancedLanguageServer>, doc: Ptr<EnhancedDocument>) Result<void, string> {
    // Clear previous analysis
    doc.symbols = hashmap.new<string, Symbol>()
    doc.imports = DynVec.new<ImportInfo>()
    doc.diagnostics = DynVec.new<Diagnostic>()
    
    // Tokenize
    tokens := lexer.tokenize(doc.content)?
    doc.tokens = tokens
    
    // Parse
    program := parser.parse(tokens)?
    doc.ast = Some(program)
    
    // Extract symbols and build symbol table
    extract_symbols(doc, program)?
    
    // Type check and collect diagnostics
    type_results := type_checker.check(program)
    type_results ?
        Result.Ok(typed_ast) => {
            // Update symbol types
            update_symbol_types(doc, typed_ast)
        }
        Result.Err(errors) => {
            // Convert type errors to diagnostics
            errors.loop((error) {
                diagnostic := type_error_to_diagnostic(error)
                DynVec.push(doc.diagnostics, diagnostic)
            }
        }
    }
    
    // Check for unused symbols
    check_unused_symbols(doc)
    
    // Check for comptime import violations
    check_comptime_imports(doc)
    
    // Update global symbol table
    update_global_symbols(server, doc)
    
    doc.dirty = false
    return Result.Ok(void)
}

// Extract symbols from AST
extract_symbols = (doc: Ptr<EnhancedDocument>, program: ast.Program) Result<void, string> {
    program.declarations.loop((decl) {
        decl ?
            | ast.Declaration.Function(func) {
                symbol := create_function_symbol(func, doc.uri)
                hashmap.insert(doc.symbols, func.name, symbol)
                
                // Extract parameter symbols
                func.parameters.loop((param) {
                    param_symbol := create_parameter_symbol(param, func.name, doc.uri)
                    hashmap.insert(doc.symbols, 
                                 string.format("{}.{}", func.name, param.name), 
                                 param_symbol)
                }
            }
            ast.Declaration.Struct(struct_def) => {
                symbol := create_struct_symbol(struct_def, doc.uri)
                hashmap.insert(doc.symbols, struct_def.name, symbol)
                
                // Extract field symbols
                struct_def.fields.loop((field) {
                    field_symbol := create_field_symbol(field, struct_def.name, doc.uri)
                    hashmap.insert(doc.symbols,
                                 string.format("{}.{}", struct_def.name, field.name),
                                 field_symbol)
                }
            }
            ast.Declaration.Enum(enum_def) => {
                symbol := create_enum_symbol(enum_def, doc.uri)
                hashmap.insert(doc.symbols, enum_def.name, symbol)
                
                // Extract variant symbols
                enum_def.variants.loop((variant) {
                    variant_symbol := create_variant_symbol(variant, enum_def.name, doc.uri)
                    hashmap.insert(doc.symbols,
                                 string.format("{}.{}", enum_def.name, variant.name),
                                 variant_symbol)
                }
            }
            ast.Declaration.Global(global) => {
                symbol := create_global_symbol(global, doc.uri)
                hashmap.insert(doc.symbols, global.name, symbol)
            }
            ast.Declaration.Import(import) => {
                import_info := create_import_info(import, doc.uri)
                DynVec.push(doc.imports, import_info)
            }
            ast.Declaration.TypeAlias(alias) => {
                symbol := create_type_alias_symbol(alias, doc.uri)
                hashmap.insert(doc.symbols, alias.name, symbol)
            }
        }
    }
    
    return Result.Ok(void)
}

// Handle hover request
handle_hover = (server: &EnhancedLanguageServer, params: TextDocumentPositionParams) Result<Option<Hover>, string>   {
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    doc.is_none() ? {
        return Result.Ok(Option.None)
    }
    
    document := doc.unwrap()
    
    // Find symbol at position
    symbol := find_symbol_at_position(document, params.position)
    symbol.is_none() ? {
        return Result.Ok(Option.None)
    }
    
    sym := symbol.unwrap()
    
    // Build hover content
    content := build_hover_content(sym)
    
    hover := Hover{
        contents: MarkupContent{
            kind: "markdown",
            value: content
        },
        range: Option.Some(sym.definition_location.range)
    }
    
    return Result.Ok(Option.Some(hover))
}

// Build hover content for symbol
build_hover_content = (symbol: &Symbol) string   {
    content := string.new()
    
    // Add signature or type info
    symbol.signature.is_some() ? {
        string.append(content, "```zen\n")
        string.append(content, symbol.signature.unwrap())
        string.append(content, "\n```\n\n")
    } else if (symbol.type_info.is_some()) {
        string.append(content, "```zen\n")
        string.append(content, format_type(symbol.type_info.unwrap()))
        string.append(content, "\n```\n\n")
    }
    
    // Add documentation
    symbol.documentation.is_some() ? {
        string.append(content, symbol.documentation.unwrap())
        string.append(content, "\n\n")
    }
    
    // Add additional info based on symbol kind
    symbol.kind ?
        SymbolKind.Function => {
            string.append(content, "**Function**\n")
        }
        SymbolKind.Struct => {
            string.append(content, "**Struct**\n")
        }
        SymbolKind.Enum => {
            string.append(content, "**Enum**\n")
        }
        SymbolKind.Variable => {
            string.append(content, "**Variable**\n")
        }
        _ => {}
    }
    
    // Add reference count
    ref_count := DynVec.len(symbol.references)
    ref_count > 0 ? {
        string.append(content, string.format("\n*{} reference{}*", 
                                            ref_count, 
                                            if (ref_count == 1) "" else "s"))
    }
    
    return content
}

// Handle go-to-definition request
handle_definition = (server: &EnhancedLanguageServer, params: TextDocumentPositionParams) Result<Option<Location>, string>   {
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    doc.is_none() ? {
        return Result.Ok(Option.None)
    }
    
    document := doc.unwrap()
    
    // Find symbol at position
    symbol_name := find_symbol_name_at_position(document, params.position)
    symbol_name.is_none() ? {
        return Result.Ok(Option.None)
    }
    
    name := symbol_name.unwrap()
    
    // Look up symbol definition
    // First check local symbols
    local_symbol := hashmap.get(document.symbols, name)
    local_symbol.is_some() ? {
        return Result.Ok(Option.Some(local_symbol.unwrap().definition_location))
    }
    
    // Check global symbols
    global_symbol := hashmap.get(server.global_symbols, name)
    global_symbol.is_some() ? {
        return Result.Ok(Option.Some(global_symbol.unwrap().definition_location))
    }
    
    // Check imported symbols
    document.imports.loop((import) {
        string.starts_with(name, import.module_name) ? {
            // Try to resolve import
            resolved := resolve_import(server, import)
            resolved.is_some() ? {
                return Result.Ok(Option.Some(resolved.unwrap()))
            }
        }
    }
    
    return Result.Ok(Option.None)
}

// Find symbol at position
find_symbol_at_position = (doc: &EnhancedDocument, pos: Position) Option<&Symbol>  {
    // Convert position to offset
    offset := position_to_offset(doc, pos)
    
    // Find token at position
    token := find_token_at_offset(doc.tokens, offset)
    token.is_none() ? {
        return Option.None
    }
    
    tok := token.unwrap()
    
    // Look up symbol by token text
    tok.type ?
        lexer.TokenType.Identifier => {
            symbol := hashmap.get(doc.symbols, tok.text)
            symbol.is_some() ? {
                return symbol
            }
            
            // Try qualified name (e.g., "struct.field")
            qualified := find_qualified_name_at_position(doc, pos)
            qualified.is_some() ? {
                return hashmap.get(doc.symbols, qualified.unwrap())
            }
        }
        _ => {}
    }
    
    return Option.None
}

// Find references to symbol
handle_references = (server: &EnhancedLanguageServer, params: ReferenceParams) Result<DynVec<Location>, string>   {
    references := DynVec.new<Location>()
    
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    doc.is_none() ? {
        return Result.Ok(references)
    }
    
    document := doc.unwrap()
    
    // Find symbol at position
    symbol_name := find_symbol_name_at_position(document, params.position)
    symbol_name.is_none() ? {
        return Result.Ok(references)
    }
    
    name := symbol_name.unwrap()
    
    // Search all documents for references
    hashmap.foreach(server.documents, (uri, doc) => {
        refs := find_references_in_document(doc, name)
        DynVec.extend(references, refs)
    })
    
    // Include definition if requested
    params.context.includeDeclaration ? {
        symbol := hashmap.get(document.symbols, name)
        symbol.is_some() ? {
            DynVec.push(references, symbol.unwrap().definition_location)
        }
    }
    
    return Result.Ok(references)
}

// Find references in document
find_references_in_document = (doc: &EnhancedDocument, symbol_name: string) DynVec<Location>   {
    references := DynVec.new<Location>()
    
    // Search through tokens
    i := 0
    while (i < DynVec.len(doc.tokens)) {
        token := doc.tokens[i]
        
        token.type == lexer.TokenType.Identifier && token.text == symbol_name ? {
            location := Location{
                uri: doc.uri,
                range: span_to_range(token.span, doc)
            }
            DynVec.push(references, location)
        }
        
        i += 1
    }
    
    return references
}

// Document symbols for outline
handle_document_symbols = (server: &EnhancedLanguageServer, params: DocumentSymbolParams) Result<DynVec<DocumentSymbol>, string>   {
    symbols := DynVec.new<DocumentSymbol>()
    
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    doc.is_none() ? {
        return Result.Ok(symbols)
    }
    
    document := doc.unwrap()
    
    // Convert symbols to DocumentSymbol format
    hashmap.foreach(document.symbols, (name, symbol) => {
        // Skip nested symbols (they'll be children)
        symbol.parent.is_none() ? {
            doc_symbol := symbol_to_document_symbol(symbol, document)
            DynVec.push(symbols, doc_symbol)
        }
    })
    
    // Sort by position
    DynVec.sort_by(symbols, (a, b) => {
        if (a.range.start.line < b.range.start.line) -1
        else if (a.range.start.line > b.range.start.line) 1
        else 0
    })
    
    return Result.Ok(symbols)
}

// Rename symbol
handle_rename = (server: MutPtr<EnhancedLanguageServer>, params: RenameParams) Result<WorkspaceEdit, string>   {
    edits := WorkspaceEdit{
        changes: hashmap.new<string, DynVec<TextEdit>>()
    }
    
    // Find all references
    ref_params := ReferenceParams{
        textDocument: params.textDocument,
        position: params.position,
        context: ReferenceContext{
            includeDeclaration: true
        }
    }
    
    references := handle_references(server, ref_params)?
    
    // Create text edits for each reference
    references.loop((location) {
        doc_edits := hashmap.get_or_insert(edits.changes, location.uri, DynVec.new<TextEdit>())
        
        edit := TextEdit{
            range: location.range,
            newText: params.newName
        }
        DynVec.push(doc_edits, edit)
    }
    
    return Result.Ok(edits)
}

// Signature help for function calls
handle_signature_help = (server: &EnhancedLanguageServer, params: SignatureHelpParams) Result<Option<SignatureHelp>, string>   {
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    doc.is_none() ? {
        return Result.Ok(Option.None)
    }
    
    document := doc.unwrap()
    
    // Find function call at position
    func_call := find_function_call_at_position(document, params.position)
    func_call.is_none() ? {
        return Result.Ok(Option.None)
    }
    
    call_info := func_call.unwrap()
    
    // Look up function symbol
    func_symbol := hashmap.get(document.symbols, call_info.function_name)
    func_symbol.is_none() ? {
        func_symbol = hashmap.get(server.global_symbols, call_info.function_name)
    }
    
    func_symbol.is_none() ? {
        return Result.Ok(Option.None)
    }
    
    symbol := func_symbol.unwrap()
    
    // Build signature information
    sig_info := SignatureInformation{
        label: symbol.signature.unwrap_or(call_info.function_name),
        documentation: symbol.documentation,
        parameters: extract_parameter_info(symbol)
    }
    
    sig_help := SignatureHelp{
        signatures: DynVec.from([sig_info]),
        activeSignature: 0,
        activeParameter: call_info.active_parameter
    }
    
    return Result.Ok(Option.Some(sig_help))
}

// Code actions for quick fixes
handle_code_actions = (server: &EnhancedLanguageServer, params: CodeActionParams) Result<DynVec<CodeAction>, string>   {
    actions := DynVec.new<CodeAction>()
    
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    doc.is_none() ? {
        return Result.Ok(actions)
    }
    
    document := doc.unwrap()
    
    // Find diagnostics in range
    document.diagnostics.loop((diagnostic) {
        ranges_overlap(diagnostic.range, params.range) ? {
            // Generate quick fixes based on diagnostic
            fixes := generate_quick_fixes(diagnostic, document)
            DynVec.extend(actions, fixes)
        }
    }
    
    // Add refactoring actions
    refactorings := generate_refactorings(document, params.range)
    DynVec.extend(actions, refactorings)
    
    return Result.Ok(actions)
}

// Check for comptime import violations
check_comptime_imports = (doc: MutPtr<EnhancedDocument>) void   {
    if (doc.ast.is_none()) return
    
    program := doc.ast.unwrap()
    
    program.statements.loop((stmt) {
        stmt ?
            ast.Statement.Comptime(block) => {
                block.statements.loop((inner_stmt) {
                    inner_stmt ?
                        ast.Statement.Assignment(assign) => {
                            // Check if it's an import
                            is_import_expression(assign.value) ? {
                                diagnostic := Diagnostic{
                                    range: span_to_range(assign.span, doc),
                                    severity: DiagnosticSeverity.Error,
                                    code: Option.Some("E001"),
                                    source: "zen",
                                    message: "Imports must not be wrapped in comptime blocks. Move import to module level.",
                                    tags: DynVec.new<DiagnosticTag>(),
                                    relatedInformation: DynVec.new<DiagnosticRelatedInformation>()
                                }
                                DynVec.push(doc.diagnostics, diagnostic)
                            }
                        }
                        _ => {}
                    }
                }
            }
            _ => {}
        }
    }
}

// Helper to check if expression is an import
is_import_expression = (expr: ast.Expression) bool   {
    expr ?
        ast.Expression.StdModule(_) => true
        ast.Expression.FunctionCall(call) => {
            call.name == "import" || string.ends_with(call.name, ".import")
        }
        _ => false
    }
}

// Helper functions
position_to_offset = (doc: &EnhancedDocument, pos: Position) usize   {
    pos.line >= DynVec.len(doc.lines) ? {
        return string.len(doc.content)
    }
    
    offset := 0usize
    line := 0u32
    while (line < pos.line) {
        offset += string.len(doc.lines[line]) + 1  // +1 for newline
        line += 1
    }
    
    offset += math.min(pos.character as usize, string.len(doc.lines[pos.line]))
    return offset
}

offset_to_position = (doc: &EnhancedDocument, offset: usize) Position   {
    current := 0usize
    line := 0u32
    
    while (line < DynVec.len(doc.lines)) {
        line_len := string.len(doc.lines[line])
        current + line_len >= offset ? {
            return Position{
                line: line,
                character: (offset - current) as u32
            }
        }
        current += line_len + 1  // +1 for newline
        line += 1
    }
    
    return Position{
        line: DynVec.len(doc.lines) as u32 - 1,
        character: string.len(doc.lines[DynVec.len(doc.lines) - 1]) as u32
    }
}

span_to_range = (span: lexer.Span, doc: &EnhancedDocument) Range   {
    return Range{
        start: offset_to_position(doc, span.start),
        end: offset_to_position(doc, span.end)
    }
}