// Enhanced Zen Language Server Protocol Implementation
// Provides advanced IDE support with hover, go-to-definition, and more

core := @std.core
io := @std.io
string := @std.string
vec := @std.vec
hashmap := @std.hashmap
fs := @std.fs
json := @std.json
result := @std.result

// Import compiler modules
lexer := @compiler.lexer
parser := @compiler.parser
type_checker := @compiler.type_checker
ast := @compiler.ast

// Symbol information for tracking definitions and references
Symbol := struct {
    name: string
    kind: SymbolKind
    type_info: Option<ast.Type>
    definition_location: Location
    references: Vec<Location>
    documentation: Option<string>
    signature: Option<string>
    parent: Option<string>  // Parent symbol for nested items
}

// Enhanced document with symbol table
EnhancedDocument := struct {
    uri: string
    version: i32
    content: string
    lines: Vec<string>  // Split content for quick line access
    tokens: Vec<lexer.Token>
    ast: Option<ast.Program>
    symbols: HashMap<string, Symbol>  // Symbol table
    imports: Vec<ImportInfo>
    diagnostics: Vec<Diagnostic>
    dirty: bool  // Needs reanalysis
}

// Import tracking
ImportInfo := struct {
    module_name: string
    alias: Option<string>
    location: Location
    resolved_path: Option<string>
}

// Enhanced Language Server
EnhancedLanguageServer := struct {
    initialized: bool
    root_uri: Option<string>
    capabilities: ServerCapabilities
    documents: HashMap<string, EnhancedDocument>
    global_symbols: HashMap<string, Symbol>  // Cross-file symbols
    workspace_symbols: Vec<Symbol>  // All workspace symbols for search
    type_definitions: HashMap<string, ast.TypeDefinition>
    import_graph: HashMap<string, Vec<string>>  // Import dependencies
}

// Position and location types (reuse from original)
Position := struct {
    line: u32
    character: u32
}

Range := struct {
    start: Position
    end: Position
}

Location := struct {
    uri: string
    range: Range
}

// Hover information
Hover := struct {
    contents: MarkupContent
    range: Option<Range>
}

MarkupContent := struct {
    kind: string  // "plaintext" or "markdown"
    value: string
}

// Symbol kinds
SymbolKind := enum {
    File = 1
    Module = 2
    Namespace = 3
    Package = 4
    Class = 5
    Method = 6
    Property = 7
    Field = 8
    Constructor = 9
    Enum = 10
    Interface = 11
    Function = 12
    Variable = 13
    Constant = 14
    String = 15
    Number = 16
    Boolean = 17
    Array = 18
    Object = 19
    Key = 20
    Null = 21
    EnumMember = 22
    Struct = 23
    Event = 24
    Operator = 25
    TypeParameter = 26
}

// Diagnostic types
Diagnostic := struct {
    range: Range
    severity: DiagnosticSeverity
    code: Option<string>
    source: string
    message: string
    tags: Vec<DiagnosticTag>
    relatedInformation: Vec<DiagnosticRelatedInformation>
}

DiagnosticSeverity := enum {
    Error = 1
    Warning = 2
    Information = 3
    Hint = 4
}

DiagnosticTag := enum {
    Unnecessary = 1
    Deprecated = 2
}

DiagnosticRelatedInformation := struct {
    location: Location
    message: string
}

// Create enhanced language server
create_enhanced_server = () EnhancedLanguageServer {
    return EnhancedLanguageServer{
        initialized: false,
        root_uri: Option.None,
        capabilities: create_server_capabilities(),
        documents: hashmap.new<string, EnhancedDocument>(),
        global_symbols: hashmap.new<string, Symbol>(),
        workspace_symbols: vec.new<Symbol>(),
        type_definitions: hashmap.new<string, ast.TypeDefinition>(),
        import_graph: hashmap.new<string, Vec<string>>()
    }
}

// Create server capabilities
create_server_capabilities = () ServerCapabilities {
    return ServerCapabilities{
        textDocumentSync: 1,  // Full sync
        completionProvider: CompletionOptions{
            triggerCharacters: vec.from([".", ":", "@", "/", "\""])
        },
        hoverProvider: true,
        definitionProvider: true,
        typeDefinitionProvider: true,
        implementationProvider: true,
        referencesProvider: true,
        documentHighlightProvider: true,
        documentSymbolProvider: true,
        workspaceSymbolProvider: true,
        codeActionProvider: true,
        codeLensProvider: CodeLensOptions{
            resolveProvider: true
        },
        documentFormattingProvider: true,
        documentRangeFormattingProvider: true,
        renameProvider: RenameOptions{
            prepareProvider: true
        },
        foldingRangeProvider: true,
        signatureHelpProvider: SignatureHelpOptions{
            triggerCharacters: vec.from(["(", ","])
        }
    }
}

// Analyze document and build symbol table
analyze_document = (server: &mut EnhancedLanguageServer, doc: &mut EnhancedDocument) Result<void, string> {
    // Clear previous analysis
    doc.symbols = hashmap.new<string, Symbol>()
    doc.imports = vec.new<ImportInfo>()
    doc.diagnostics = vec.new<Diagnostic>()
    
    // Tokenize
    tokens := lexer.tokenize(doc.content)?
    doc.tokens = tokens
    
    // Parse
    program := parser.parse(tokens)?
    doc.ast = Option.Some(program)
    
    // Extract symbols and build symbol table
    extract_symbols(doc, program)?
    
    // Type check and collect diagnostics
    type_results := type_checker.check(program)
    match type_results {
        Result.Ok(typed_ast) => {
            // Update symbol types
            update_symbol_types(doc, typed_ast)
        }
        Result.Err(errors) => {
            // Convert type errors to diagnostics
            for (error in errors) {
                diagnostic := type_error_to_diagnostic(error)
                vec.push(doc.diagnostics, diagnostic)
            }
        }
    }
    
    // Check for unused symbols
    check_unused_symbols(doc)
    
    // Check for comptime import violations
    check_comptime_imports(doc)
    
    // Update global symbol table
    update_global_symbols(server, doc)
    
    doc.dirty = false
    return Result.Ok(void)
}

// Extract symbols from AST
extract_symbols = (doc: &mut EnhancedDocument, program: ast.Program) Result<void, string> {
    for (decl in program.declarations) {
        match decl {
            ast.Declaration.Function(func) => {
                symbol := create_function_symbol(func, doc.uri)
                hashmap.insert(doc.symbols, func.name, symbol)
                
                // Extract parameter symbols
                for (param in func.parameters) {
                    param_symbol := create_parameter_symbol(param, func.name, doc.uri)
                    hashmap.insert(doc.symbols, 
                                 string.format("{}.{}", func.name, param.name), 
                                 param_symbol)
                }
            }
            ast.Declaration.Struct(struct_def) => {
                symbol := create_struct_symbol(struct_def, doc.uri)
                hashmap.insert(doc.symbols, struct_def.name, symbol)
                
                // Extract field symbols
                for (field in struct_def.fields) {
                    field_symbol := create_field_symbol(field, struct_def.name, doc.uri)
                    hashmap.insert(doc.symbols,
                                 string.format("{}.{}", struct_def.name, field.name),
                                 field_symbol)
                }
            }
            ast.Declaration.Enum(enum_def) => {
                symbol := create_enum_symbol(enum_def, doc.uri)
                hashmap.insert(doc.symbols, enum_def.name, symbol)
                
                // Extract variant symbols
                for (variant in enum_def.variants) {
                    variant_symbol := create_variant_symbol(variant, enum_def.name, doc.uri)
                    hashmap.insert(doc.symbols,
                                 string.format("{}.{}", enum_def.name, variant.name),
                                 variant_symbol)
                }
            }
            ast.Declaration.Global(global) => {
                symbol := create_global_symbol(global, doc.uri)
                hashmap.insert(doc.symbols, global.name, symbol)
            }
            ast.Declaration.Import(import) => {
                import_info := create_import_info(import, doc.uri)
                vec.push(doc.imports, import_info)
            }
            ast.Declaration.TypeAlias(alias) => {
                symbol := create_type_alias_symbol(alias, doc.uri)
                hashmap.insert(doc.symbols, alias.name, symbol)
            }
        }
    }
    
    return Result.Ok(void)
}

// Handle hover request
handle_hover = (server: &EnhancedLanguageServer, params: TextDocumentPositionParams) Result<Option<Hover>, string> {
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    if (doc.is_none()) {
        return Result.Ok(Option.None)
    }
    
    document := doc.unwrap()
    
    // Find symbol at position
    symbol := find_symbol_at_position(document, params.position)
    if (symbol.is_none()) {
        return Result.Ok(Option.None)
    }
    
    sym := symbol.unwrap()
    
    // Build hover content
    content := build_hover_content(sym)
    
    hover := Hover{
        contents: MarkupContent{
            kind: "markdown",
            value: content
        },
        range: Option.Some(sym.definition_location.range)
    }
    
    return Result.Ok(Option.Some(hover))
}

// Build hover content for symbol
build_hover_content = (symbol: &Symbol) string {
    content := string.new()
    
    // Add signature or type info
    if (symbol.signature.is_some()) {
        string.append(content, "```zen\n")
        string.append(content, symbol.signature.unwrap())
        string.append(content, "\n```\n\n")
    } else if (symbol.type_info.is_some()) {
        string.append(content, "```zen\n")
        string.append(content, format_type(symbol.type_info.unwrap()))
        string.append(content, "\n```\n\n")
    }
    
    // Add documentation
    if (symbol.documentation.is_some()) {
        string.append(content, symbol.documentation.unwrap())
        string.append(content, "\n\n")
    }
    
    // Add additional info based on symbol kind
    match symbol.kind {
        SymbolKind.Function => {
            string.append(content, "**Function**\n")
        }
        SymbolKind.Struct => {
            string.append(content, "**Struct**\n")
        }
        SymbolKind.Enum => {
            string.append(content, "**Enum**\n")
        }
        SymbolKind.Variable => {
            string.append(content, "**Variable**\n")
        }
        _ => {}
    }
    
    // Add reference count
    ref_count := vec.len(symbol.references)
    if (ref_count > 0) {
        string.append(content, string.format("\n*{} reference{}*", 
                                            ref_count, 
                                            if (ref_count == 1) "" else "s"))
    }
    
    return content
}

// Handle go-to-definition request
handle_definition = (server: &EnhancedLanguageServer, params: TextDocumentPositionParams) Result<Option<Location>, string> {
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    if (doc.is_none()) {
        return Result.Ok(Option.None)
    }
    
    document := doc.unwrap()
    
    // Find symbol at position
    symbol_name := find_symbol_name_at_position(document, params.position)
    if (symbol_name.is_none()) {
        return Result.Ok(Option.None)
    }
    
    name := symbol_name.unwrap()
    
    // Look up symbol definition
    // First check local symbols
    local_symbol := hashmap.get(document.symbols, name)
    if (local_symbol.is_some()) {
        return Result.Ok(Option.Some(local_symbol.unwrap().definition_location))
    }
    
    // Check global symbols
    global_symbol := hashmap.get(server.global_symbols, name)
    if (global_symbol.is_some()) {
        return Result.Ok(Option.Some(global_symbol.unwrap().definition_location))
    }
    
    // Check imported symbols
    for (import in document.imports) {
        if (string.starts_with(name, import.module_name)) {
            // Try to resolve import
            resolved := resolve_import(server, import)
            if (resolved.is_some()) {
                return Result.Ok(Option.Some(resolved.unwrap()))
            }
        }
    }
    
    return Result.Ok(Option.None)
}

// Find symbol at position
find_symbol_at_position = (doc: &EnhancedDocument, pos: Position) Option<&Symbol> {
    // Convert position to offset
    offset := position_to_offset(doc, pos)
    
    // Find token at position
    token := find_token_at_offset(doc.tokens, offset)
    if (token.is_none()) {
        return Option.None
    }
    
    tok := token.unwrap()
    
    // Look up symbol by token text
    match tok.type {
        lexer.TokenType.Identifier => {
            symbol := hashmap.get(doc.symbols, tok.text)
            if (symbol.is_some()) {
                return symbol
            }
            
            // Try qualified name (e.g., "struct.field")
            qualified := find_qualified_name_at_position(doc, pos)
            if (qualified.is_some()) {
                return hashmap.get(doc.symbols, qualified.unwrap())
            }
        }
        _ => {}
    }
    
    return Option.None
}

// Find references to symbol
handle_references = (server: &EnhancedLanguageServer, params: ReferenceParams) Result<Vec<Location>, string> {
    references := vec.new<Location>()
    
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    if (doc.is_none()) {
        return Result.Ok(references)
    }
    
    document := doc.unwrap()
    
    // Find symbol at position
    symbol_name := find_symbol_name_at_position(document, params.position)
    if (symbol_name.is_none()) {
        return Result.Ok(references)
    }
    
    name := symbol_name.unwrap()
    
    // Search all documents for references
    hashmap.foreach(server.documents, (uri, doc) => {
        refs := find_references_in_document(doc, name)
        vec.extend(references, refs)
    })
    
    // Include definition if requested
    if (params.context.includeDeclaration) {
        symbol := hashmap.get(document.symbols, name)
        if (symbol.is_some()) {
            vec.push(references, symbol.unwrap().definition_location)
        }
    }
    
    return Result.Ok(references)
}

// Find references in document
find_references_in_document = (doc: &EnhancedDocument, symbol_name: string) Vec<Location> {
    references := vec.new<Location>()
    
    // Search through tokens
    i := 0
    while (i < vec.len(doc.tokens)) {
        token := doc.tokens[i]
        
        if (token.type == lexer.TokenType.Identifier && token.text == symbol_name) {
            location := Location{
                uri: doc.uri,
                range: span_to_range(token.span, doc)
            }
            vec.push(references, location)
        }
        
        i += 1
    }
    
    return references
}

// Document symbols for outline
handle_document_symbols = (server: &EnhancedLanguageServer, params: DocumentSymbolParams) Result<Vec<DocumentSymbol>, string> {
    symbols := vec.new<DocumentSymbol>()
    
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    if (doc.is_none()) {
        return Result.Ok(symbols)
    }
    
    document := doc.unwrap()
    
    // Convert symbols to DocumentSymbol format
    hashmap.foreach(document.symbols, (name, symbol) => {
        // Skip nested symbols (they'll be children)
        if (symbol.parent.is_none()) {
            doc_symbol := symbol_to_document_symbol(symbol, document)
            vec.push(symbols, doc_symbol)
        }
    })
    
    // Sort by position
    vec.sort_by(symbols, (a, b) => {
        if (a.range.start.line < b.range.start.line) -1
        else if (a.range.start.line > b.range.start.line) 1
        else 0
    })
    
    return Result.Ok(symbols)
}

// Rename symbol
handle_rename = (server: &mut EnhancedLanguageServer, params: RenameParams) Result<WorkspaceEdit, string> {
    edits := WorkspaceEdit{
        changes: hashmap.new<string, Vec<TextEdit>>()
    }
    
    // Find all references
    ref_params := ReferenceParams{
        textDocument: params.textDocument,
        position: params.position,
        context: ReferenceContext{
            includeDeclaration: true
        }
    }
    
    references := handle_references(server, ref_params)?
    
    // Create text edits for each reference
    for (location in references) {
        doc_edits := hashmap.get_or_insert(edits.changes, location.uri, vec.new<TextEdit>())
        
        edit := TextEdit{
            range: location.range,
            newText: params.newName
        }
        vec.push(doc_edits, edit)
    }
    
    return Result.Ok(edits)
}

// Signature help for function calls
handle_signature_help = (server: &EnhancedLanguageServer, params: SignatureHelpParams) Result<Option<SignatureHelp>, string> {
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    if (doc.is_none()) {
        return Result.Ok(Option.None)
    }
    
    document := doc.unwrap()
    
    // Find function call at position
    func_call := find_function_call_at_position(document, params.position)
    if (func_call.is_none()) {
        return Result.Ok(Option.None)
    }
    
    call_info := func_call.unwrap()
    
    // Look up function symbol
    func_symbol := hashmap.get(document.symbols, call_info.function_name)
    if (func_symbol.is_none()) {
        func_symbol = hashmap.get(server.global_symbols, call_info.function_name)
    }
    
    if (func_symbol.is_none()) {
        return Result.Ok(Option.None)
    }
    
    symbol := func_symbol.unwrap()
    
    // Build signature information
    sig_info := SignatureInformation{
        label: symbol.signature.unwrap_or(call_info.function_name),
        documentation: symbol.documentation,
        parameters: extract_parameter_info(symbol)
    }
    
    sig_help := SignatureHelp{
        signatures: vec.from([sig_info]),
        activeSignature: 0,
        activeParameter: call_info.active_parameter
    }
    
    return Result.Ok(Option.Some(sig_help))
}

// Code actions for quick fixes
handle_code_actions = (server: &EnhancedLanguageServer, params: CodeActionParams) Result<Vec<CodeAction>, string> {
    actions := vec.new<CodeAction>()
    
    // Get document
    doc := hashmap.get(server.documents, params.textDocument.uri)
    if (doc.is_none()) {
        return Result.Ok(actions)
    }
    
    document := doc.unwrap()
    
    // Find diagnostics in range
    for (diagnostic in document.diagnostics) {
        if (ranges_overlap(diagnostic.range, params.range)) {
            // Generate quick fixes based on diagnostic
            fixes := generate_quick_fixes(diagnostic, document)
            vec.extend(actions, fixes)
        }
    }
    
    // Add refactoring actions
    refactorings := generate_refactorings(document, params.range)
    vec.extend(actions, refactorings)
    
    return Result.Ok(actions)
}

// Check for comptime import violations
check_comptime_imports = (doc: &mut EnhancedDocument) void {
    if (doc.ast.is_none()) return
    
    program := doc.ast.unwrap()
    
    for (stmt in program.statements) {
        match stmt {
            ast.Statement.Comptime(block) => {
                for (inner_stmt in block.statements) {
                    match inner_stmt {
                        ast.Statement.Assignment(assign) => {
                            // Check if it's an import
                            if (is_import_expression(assign.value)) {
                                diagnostic := Diagnostic{
                                    range: span_to_range(assign.span, doc),
                                    severity: DiagnosticSeverity.Error,
                                    code: Option.Some("E001"),
                                    source: "zen",
                                    message: "Imports must not be wrapped in comptime blocks. Move import to module level.",
                                    tags: vec.new<DiagnosticTag>(),
                                    relatedInformation: vec.new<DiagnosticRelatedInformation>()
                                }
                                vec.push(doc.diagnostics, diagnostic)
                            }
                        }
                        _ => {}
                    }
                }
            }
            _ => {}
        }
    }
}

// Helper to check if expression is an import
is_import_expression = (expr: ast.Expression) bool {
    match expr {
        ast.Expression.StdModule(_) => true
        ast.Expression.FunctionCall(call) => {
            call.name == "import" || string.ends_with(call.name, ".import")
        }
        _ => false
    }
}

// Helper functions
position_to_offset = (doc: &EnhancedDocument, pos: Position) usize {
    if (pos.line >= vec.len(doc.lines)) {
        return string.len(doc.content)
    }
    
    offset := 0usize
    line := 0u32
    while (line < pos.line) {
        offset += string.len(doc.lines[line]) + 1  // +1 for newline
        line += 1
    }
    
    offset += math.min(pos.character as usize, string.len(doc.lines[pos.line]))
    return offset
}

offset_to_position = (doc: &EnhancedDocument, offset: usize) Position {
    current := 0usize
    line := 0u32
    
    while (line < vec.len(doc.lines)) {
        line_len := string.len(doc.lines[line])
        if (current + line_len >= offset) {
            return Position{
                line: line,
                character: (offset - current) as u32
            }
        }
        current += line_len + 1  // +1 for newline
        line += 1
    }
    
    return Position{
        line: vec.len(doc.lines) as u32 - 1,
        character: string.len(doc.lines[vec.len(doc.lines) - 1]) as u32
    }
}

span_to_range = (span: lexer.Span, doc: &EnhancedDocument) Range {
    return Range{
        start: offset_to_position(doc, span.start),
        end: offset_to_position(doc, span.end)
    }
}