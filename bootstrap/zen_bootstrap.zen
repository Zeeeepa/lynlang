// Zen Bootstrap Compiler
// A minimal compiler that can compile itself
// This is the first step towards full self-hosting

{ io } = @std.io
{ fs } = @std.fs
{ string } = @std.string
{ vec } = @std.vec
{ core } = @std.core

// Token types for the lexer
TokenType:
    .Identifier |
    .Number |
    .String |
    .Keyword |
    .Operator |
    .Symbol |
    .Eof

// Token structure
Token: {
    type: TokenType,
    value: string,
    line: i32,
    column: i32,
}

// Lexer state
Lexer: {
    input: string,
    position: i32,
    read_position: i32,
    current_char: char,
    line: i32,
    column: i32,
}

// Create a new lexer
lexer_new = (input: string) Lexer   {
    l := Lexer {
        input = input,
        position = 0,
        read_position = 0,
        current_char = '\0',
        line = 1,
        column = 1,
    }
    lexer_read_char(&l)
    return l
}

// Read the next character
lexer_read_char = (l: *Lexer) void   {
    l.read_position >= l.input.len() ?
        | true { { l.current_char = '\0'  }}
        | false {
            l.current_char = l.input[l.read_position]
            l.position = l.read_position
            l.read_position = l.read_position + 1
            
            l.current_char == '\n' ?
                | true {
                    l.line = l.line + 1
                    l.column = 1
                }
                | false {
                    l.column = l.column + 1
                }
        }
}

// Peek at the next character
lexer_peek_char = (l: *Lexer) char   {
    l.read_position >= l.input.len() ?
        | true { { return '\0'  }}
        | false { { return l.input[l.read_position]  }}
}

// Skip whitespace
lexer_skip_whitespace = (l: *Lexer) void   {
    loop (l.current_char == ' ' || l.current_char == '\t' || 
          l.current_char == '\r' || l.current_char == '\n') {
        lexer_read_char(l)
    }
}

// Check if character is a letter
is_letter = (ch: char) bool   {
    return (ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z') || ch == '_'
}

// Check if character is a digit
is_digit = (ch: char) bool   {
    return ch >= '0' && ch <= '9'
}

// Read an identifier
lexer_read_identifier = (l: *Lexer) string   {
    start := l.position
    loop (is_letter(l.current_char) || is_digit(l.current_char)) {
        lexer_read_char(l)
    }
    return string.substring(l.input, start, l.position)
}

// Read a number
lexer_read_number = (l: *Lexer) string   {
    start := l.position
    loop is_digit(l.current_char) {
        lexer_read_char(l)
    }
    
    // Check for decimal point
    l.current_char == '.' && is_digit(lexer_peek_char(l)) ?
        | true {
            lexer_read_char(l) // consume '.'
            loop is_digit(l.current_char) {
                lexer_read_char(l)
            }
        }
        | false {}
    
    return string.substring(l.input, start, l.position)
}

// Read a string literal
lexer_read_string = (l: *Lexer) string   {
    lexer_read_char(l) // skip opening quote
    start := l.position
    
    loop l.current_char != '"' && l.current_char != '\0' {
        l.current_char == '\\' ?
            | true {
                lexer_read_char(l) // skip escape char
                lexer_read_char(l) // skip escaped char
            }
            | false {
                lexer_read_char(l)
            }
    }
    
    result := string.substring(l.input, start, l.position)
    lexer_read_char(l) // skip closing quote
    return result
}

// Get next token
lexer_next_token = (l: *Lexer) Token   {
    lexer_skip_whitespace(l)
    
    tok := Token {
        type = TokenType.Eof,
        value = "",
        line = l.line,
        column = l.column,
    }
    
    l.current_char ?
        | '\0' {
            tok.type = TokenType.Eof
            return tok
        }
        | '+' | '-' | '*' | '/' | '=' | '<' | '>' | '!' {
            tok.type = TokenType.Operator
            tok.value = string.from_char(l.current_char)
            
            // Check for two-character operators
            next := lexer_peek_char(l)
            (l.current_char == '=' && next == '=') ||
            (l.current_char == '!' && next == '=') ||
            (l.current_char == '<' && next == '=') ||
            (l.current_char == '>' && next == '=') ||
            (l.current_char == ':' && next == '=') ?
                | true {
                    lexer_read_char(l)
                    tok.value = tok.value + string.from_char(l.current_char)
                }
                | false {}
            
            lexer_read_char(l)
        }
        | '(' | ')' | '{' | '}' | '[' | ']' | ',' | ';' | ':' | '.' {
            tok.type = TokenType.Symbol
            tok.value = string.from_char(l.current_char)
            lexer_read_char(l)
        }
        | '"' {
            tok.type = TokenType.String
            tok.value = lexer_read_string(l)
        }
        | _ {
            is_letter(l.current_char) ?
                | true {
                    tok.value = lexer_read_identifier(l)
                    // Check if it's a keyword
                    is_keyword(tok.value) ?
                        | true { { tok.type = TokenType.Keyword  }}
                        | false { { tok.type = TokenType.Identifier  }}
                }
                | false {
                    is_digit(l.current_char) ?
                        | true {
                            tok.type = TokenType.Number
                            tok.value = lexer_read_number(l)
                        }
                        | false {
                            // Unknown character
                            tok.value = string.from_char(l.current_char)
                            lexer_read_char(l)
                        }
                }
        }
    
    return tok
}

// Check if a string is a keyword
is_keyword = (s: string) bool   {
    return s == "loop" || s == "return" ||
           s == "true" || s == "false" || s == "void" || s == "i32" ||
           s == "i64" || s == "f32" || s == "f64" || s == "bool" ||
           s == "string" || s == "char" || s == "comptime"
}

// AST Node types
AstNode:
    .Program { declarations: Vec<AstNode> } |
    .Function { name: string, params: Vec<(string, string)>, return_type: string, body: Vec<AstNode> } |
    .Variable { name: string, type: string, value: AstNode } |
    .IntLiteral { value: i64 } |
    .StringLiteral { value: string } |
    .Identifier { name: string } |
    .BinaryOp { op: string, left: AstNode, right: AstNode } |
    .FunctionCall { name: string, args: Vec<AstNode> } |
    .Return { value: AstNode } |
    .PatternMatch { condition: AstNode, then_body: Vec<AstNode>, else_body: Vec<AstNode> }

// Parser state
Parser: {
    tokens: Vec<Token>,
    current: i32,
}

// Create a new parser
parser_new = (tokens: Vec<Token>) Parser   {
    return Parser {
        tokens = tokens,
        current = 0,
    }
}

// Get current token
parser_current = (p: *Parser) Token   {
    p.current >= p.tokens.len() ?
        | true { { return Token { type = TokenType.Eof, value = "", line = 0, column = 0  }} }
        | false { { return p.tokens[p.current]  }}
}

// Advance to next token
parser_advance = (p: *Parser) void   {
    p.current < p.tokens.len() ?
        | true { { p.current = p.current + 1  }}
        | false {}
}

// Check if current token matches
parser_check = (p: *Parser, type: TokenType) bool   {
    tok := parser_current(p)
    return tok.type == type
}

// Check if current token is a specific value
parser_check_value = (p: *Parser, value: string) bool   {
    tok := parser_current(p)
    return tok.value == value
}

// Parse the program
parser_parse = (p: *Parser) AstNode   {
    declarations := vec.new<AstNode>()
    
    loop !parser_check(p, TokenType.Eof) {
        decl := parser_parse_declaration(p)
        vec.push(declarations, decl)
    }
    
    return AstNode { .Program { declarations = declarations } }
}

// Parse a declaration (function or variable)
parser_parse_declaration = (p: *Parser) AstNode   {
    // For now, just handle simple function declarations
    name_tok := parser_current(p)
    parser_advance(p)
    
    parser_check_value(p, "=") ?
        | true {
            parser_advance(p) // skip '='
            
            // Check if it's a function
            parser_check_value(p, "(") ?
                | true {
                    return parser_parse_function(name_tok.value, p)
                }
                | false {
                    // Variable declaration
                    value := parser_parse_expression(p)
                    return AstNode { .Variable { name = name_tok.value, type = "auto", value = value } }
                }
        }
        | false {
            // Error: expected '='
            io.print("Error: expected '=' after identifier\n")
            return AstNode { .IntLiteral { value = 0 } }
        }
}

// Parse a function
parser_parse_function = (p: *Parser, name: string) AstNode   {
    parser_advance(p) // skip '('
    
    // Parse parameters (simplified)
    params := vec.new<(string, string)>()
    
    !parser_check_value(p, ")") ?
        | true {
            // Simple parameter parsing
            loop {
                param_name := parser_current(p)
                parser_advance(p)
                
                parser_check_value(p, ":") ?
                    | true {
                        parser_advance(p)
                        type_tok := parser_current(p)
                        parser_advance(p)
                        vec.push(params, (param_name.value, type_tok.value))
                    }
                    | false {
                        vec.push(params, (param_name.value, "auto"))
                    }
                
                parser_check_value(p, ",") ?
                    | true {
                        parser_advance(p)
                    }
                    | false {
                        break
                    }
            }
        }
        | false {}
    
    parser_advance(p) // skip ')'
    
    // Parse return type
    return_type := "void"
    !parser_check_value(p, "{") ?
        | true {
            type_tok := parser_current(p)
            return_type = type_tok.value
            parser_advance(p)
        }
        | false {}
    
    // Parse body
    parser_advance(p) // skip '{'
    body := vec.new<AstNode>()
    
    loop !parser_check_value(p, "}") {
        stmt := parser_parse_statement(p)
        vec.push(body, stmt)
    }
    
    parser_advance(p) // skip '}'
    
    return AstNode { .Function { name = name, params = params, return_type = return_type, body = body } }
}

// Parse a statement
parser_parse_statement = (p: *Parser) AstNode   {
    parser_check(p, TokenType.Keyword) ?
        | true {
            tok := parser_current(p)
            tok.value ?
                | "return" {
                    parser_advance(p)
                    value := parser_parse_expression(p)
                    return AstNode { .Return { value = value } }
                }
                | _ {
                    return parser_parse_expression(p)
                }
        }
        | false {
            return parser_parse_expression(p)
        }
}

// Parse an expression (simplified)
parser_parse_expression = (p: *Parser) AstNode   {
    left := parser_parse_primary(p)
    
    // Check for binary operators
    parser_check(p, TokenType.Operator) ?
        | true {
            op := parser_current(p)
            parser_advance(p)
            right := parser_parse_expression(p)
            return AstNode { .BinaryOp { op = op.value, left = left, right = right } }
        }
        | false {
            return left
        }
}

// Parse primary expression
parser_parse_primary = (p: *Parser) AstNode   {
    tok := parser_current(p)
    
    tok.type ?
        | TokenType.Number {
            parser_advance(p)
            value := string.to_int(tok.value)
            return AstNode { .IntLiteral { value = value } }
        }
        | TokenType.String {
            parser_advance(p)
            return AstNode { .StringLiteral { value = tok.value } }
        }
        | TokenType.Identifier {
            parser_advance(p)
            
            // Check for function call
            parser_check_value(p, "(") ?
                | true {
                    parser_advance(p)
                    args := vec.new<AstNode>()
                    
                    !parser_check_value(p, ")") ?
                        | true {
                            loop {
                                arg := parser_parse_expression(p)
                                vec.push(args, arg)
                                
                                parser_check_value(p, ",") ?
                                    | true { { parser_advance(p)  }}
                                    | false { { break  }}
                            }
                        }
                        | false {}
                    
                    parser_advance(p) // skip ')'
                    return AstNode { .FunctionCall { name = tok.value, args = args } }
                }
                | false {
                    return AstNode { .Identifier { name = tok.value } }
                }
        }
        | _ {
            parser_advance(p)
            return AstNode { .IntLiteral { value = 0 } }
        }
}

// Code generator - generates simple C code
codegen_generate = (ast: AstNode) string   {
    ast ?
        | .Program { declarations } {
            output := "#include <stdio.h>\n\n"
            
            i := 0
            loop i < declarations.len() {
                output = output + codegen_generate(declarations[i]) + "\n"
                i = i + 1
            }
            
            return output
        }
        | .Function { name, params, return_type, body } {
            output := return_type + " " + name + "("
            
            i := 0
            loop i < params.len() {
                param := params[i]
                output = output + param.1 + " " + param.0
                i < params.len() - 1 ?
                    | true { { output = output + ", "  }}
                    | false {}
                i = i + 1
            }
            
            output = output + ") {\n"
            
            i = 0
            loop i < body.len() {
                output = output + "    " + codegen_generate(body[i]) + ";\n"
                i = i + 1
            }
            
            output = output + "}\n"
            return output
        }
        | .Return { value } {
            return "return " + codegen_generate(value)
        }
        | .IntLiteral { value } {
            return string.from_int(value)
        }
        | .StringLiteral { value } {
            return "\"" + value + "\""
        }
        | .Identifier { name } {
            return name
        }
        | .FunctionCall { name, args } {
            output := name + "("
            
            i := 0
            loop i < args.len() {
                output = output + codegen_generate(args[i])
                i < args.len() - 1 ?
                    | true { { output = output + ", "  }}
                    | false {}
                i = i + 1
            }
            
            output = output + ")"
            return output
        }
        | .BinaryOp { op, left, right } {
            return codegen_generate(left) + " " + op + " " + codegen_generate(right)
        }
        | _ {
            return ""
        }
}

// Main compiler function
compile_file = (input_path: string, output_path: string) i32   {
    // Read input file
    input := fs.read_file(input_path)
    input.is_error() ?
        | true {
            io.print("Error: Could not read file ")
            io.print(input_path)
            io.print("\n")
            return 1
        }
        | false {}
    
    content := input.unwrap()
    
    // Lex the input
    lexer := lexer_new(content)
    tokens := vec.new<Token>()
    
    loop {
        tok := lexer_next_token(&lexer)
        vec.push(tokens, tok)
        tok.type == TokenType.Eof ?
            | true { { break  }}
            | false {}
    }
    
    // Parse the tokens
    parser := parser_new(tokens)
    ast := parser_parse(&parser)
    
    // Generate code
    output := codegen_generate(ast)
    
    // Write output file
    result := fs.write_file(output_path, output)
    result.is_error() ?
        | true {
            io.print("Error: Could not write file ")
            io.print(output_path)
            io.print("\n")
            return 1
        }
        | false {}
    
    io.print("Successfully compiled ")
    io.print(input_path)
    io.print(" to ")
    io.print(output_path)
    io.print("\n")
    
    return 0
}

// Main entry point
main = () i32   {
    io.print("Zen Bootstrap Compiler v0.1\n")
    io.print("===========================\n\n")
    
    // For now, hardcode the test file
    result := compile_file("test.zen", "test.c")
    
    return result
}